{"version":3,"sources":["../../src/tasks/deploy.ts","../../src/constants/tasks.ts","../../src/runtime.ts","../../src/errors/errors.ts","../../src/artifacts.ts","../../src/errors/parser.ts","../../src/cli.ts","../../src/internal/assertions.ts","../../src/type-extensions.ts","../../src/tasks/simulation/logs.ts","../../src/simulation/config.ts","../../src/tasks/simulation/start.ts","../../src/simulation/compose.ts","../../src/simulation/assets/Dockerfile.conf","../../src/simulation/assets/nginx.conf","../../src/tasks/simulation/stop.ts","../../src/tasks/transactions/subtask.sign-and-send.ts","../../src/tasks/export.deployments.typescript.ts","../../src/tasks/healthcheck/validate-safe-configs.ts","../../src/tasks/healthcheck/validate-rpcs.ts"],"names":["task","formatEid","pMemoize","abi","environment","eid","splitCommaSeparated","logLevel","stage","logger","printLogo","createLogger","setDefaultLogLevel","action","printJson","join","pipe","spawnSync","endpointIdToStage","isFile","subtask","pluralizeNoun","printBoolean","types","_a"],"mappings":";AAAA,SAAS,QAAAA,aAAY;AAErB,SAAS,oBAAoB;;;ACFtB,IAAM,iBAAiB;AAEvB,IAAM,wCAAwC;AAE9C,IAAM,2BAA2B;AAEjC,IAAM,gCAAgC;AAEtC,IAAM,+BAA+B;AAErC,IAAM,+BAA+B;AAErC,IAAM,gCAAgC;AAEtC,IAAM,wBAAwB;;;ADVrC;AAAA,EAEI;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,OACG;AAEP,SAAS,mBAAmB,WAAW,cAAc,cAAc;AACnE,SAAS,aAAAC,kBAAiB;;;AER1B,OAAOC,eAAc;;;ACLd,IAAM,qBAAN,cAAiC,MAAM;AAAC;;;ACD/C,SAAS,iBAAiB;AAE1B,OAAO,cAAc;AAOd,IAAM,kBAAkB,SAAS,OAAO,MAAM,6BAA6B,MAA2B;AAV7G;AAcI,QAAM,qBAAoB,eAAI,OAAO,aAAX,mBAAqB,cAArB,YAAkC,CAAC;AAC7D,QAAM,iBAA2B;AAAA,IAC7B,IAAI,OAAO,MAAM;AAAA,IACjB,IAAI,OAAO,MAAM;AAAA,IACjB,GAAG,kBAAkB,QAAQ,CAAC,EAAE,UAAU,MAAM,SAAS;AAAA,EAC7D;AAGA,QAAM,mBAAmB,eAAe,IAAI,CAAC,SAAS,IAAI,UAAU,IAAI,CAAC;AAGzE,QAAM,cAAc,MAAM,QAAQ,IAAI,iBAAiB,IAAI,mBAAmB,CAAC;AAE/E,SAAO,YAAY,KAAK;AAC5B,CAAC;AAED,IAAM,sBAAsB,OAAO,oBAA+B;AAE9D,QAAM,sBAAsB,MAAM,gBAAgB,0BAA0B;AAE5E,SAAO,oBAAoB,IAAI,CAAC,SAAS,gBAAgB,iBAAiB,IAAI,CAAC;AACnF;AAEO,IAAM,kBAAkB,CAC3B,aAC4C,SAAS,SAAS;;;ACtClE,SAAS,gBAAgB;AACzB,SAAuB,iCAAiC;AACxD,SAAS,uBAAuB;AAEhC,OAAOA,eAAc;AAQrB,IAAM,yBAAyBA,UAAS,YAAmC;AAEvE,QAAM,YAAY,MAAM,gBAAgB;AAGxC,QAAM,MAAM,UAAU,QAAQ,CAAC,aAAa,SAAS,GAAG,EAAE,OAAO,eAAe;AAIhF,QAAM,kBAAkB,OAAO,OAAO,OAAO,YAAY,IAAI,IAAI,CAACC,SAAQ,CAAC,KAAK,UAAUA,IAAG,GAAGA,IAAG,CAAC,CAAC,CAAC;AAItG,SAAO,EAAE,KAAK,IAAkB,UAAU,IAAI,SAAS,gBAAgB,GAAG,eAAe,EAAE;AAC/F,CAAC;;;AHjBD,SAAS,sBAAsB;AAC/B,SAAS,0BAA0B;AACnC,SAAS,eAAe,+CAA+C;AAEvE,SAAwC,iBAAiB;AACzD,SAAS,6BAA6B;AAEtC,OAAO,aAAa;AACpB,SAAS,SAAS,YAAY;AAqDvB,IAAM,oBAAoB,MAAsB;AAMnD,MAAI;AACA,WAAO,eAAe,kBAAkB;AAAA,EAC5C,SAAS,OAAgB;AACrB,UAAM,IAAI,mBAAmB,kCAAkC,KAAK,EAAE;AAAA,EAC1E;AACJ;AASO,IAAM,+BAA+B,MAAiC;AAEzE,QAAM,UAAU,kBAAkB;AAMlC,MAAI;AACA,WAAO,QAAQ,6BAA6B;AAAA,EAChD,SAAS,OAAgB;AACrB,UAAM,IAAI,mBAAmB,8CAA8C,KAAK,EAAE;AAAA,EACtF;AACJ;AAcO,IAAM,sBAA+DD,UAAS,OAAO,gBAAgB;AACxG,QAAM,UAAU,kBAAkB;AAClC,QAAME,eAAc,6BAA6B;AAEjD,MAAI;AAGA,WAAO,IAAI;AAAA,MACPA,aAAY;AAAA,MACZ;AAAA,QACI,GAAGA,aAAY;AAAA,QACf,SAAS;AAAA,MACb;AAAA,MACAA,aAAY;AAAA,MACZA,aAAY;AAAA,MACZ,QAAQ;AAAA,MACRA,aAAY;AAAA,MACZ,QAAQ;AAAA;AAAA;AAAA;AAAA,IAIZ;AAAA,EACJ,SAAS,OAAgB;AACrB,UAAM,IAAI,mBAAmB,gDAAgD,KAAK,EAAE;AAAA,EACxF;AACJ,CAAC;AA6GM,IAAM,uBAAuB;AAAA,EAChC,CAAC,MAAiC,6BAA6B,MAA8C;AAEzG,UAAM,iBAAiB,OAAO,QAAQ,IAAI,OAAO,QAAQ;AAEzD,UAAM,aAAa,eAAe;AAAA,MAC9B,CAAC,CAAC,aAAa,aAAa,MAAM,CAAC,aAAa,cAAc,GAAG;AAAA,IACrE;AAEA,UAAM,oBAAoB,OAAO,YAAY,UAAU;AAMvD,UAAM,2BAA2B,WAAW,OAAO,CAAC,CAAC,GAAGC,IAAG,MAAMA,QAAO,IAAI;AAC5E,UAAM,2BAA2B,OAAO,YAAY,wBAAwB;AAG5E,UAAM,iBAAiB,IAAI,IAAI,OAAO,OAAO,wBAAwB,CAAC;AACtE,UAAM,kBAAkB,IAAI,IAAI,OAAO,KAAK,wBAAwB,CAAC;AAGrE,QAAI,eAAe,SAAS,gBAAgB,MAAM;AAC9C,aAAO;AAAA,IACX;AAUA,UAAM,yBAAyB,MAAM,KAAK,cAAc,EAEnD;AAAA,MAAI,CAACA,SACF,yBAAyB;AAAA,QAAQ,CAAC,CAAC,aAAa,UAAU,MACtDA,SAAQ,aAAa,CAAC,WAAW,IAAI,CAAC;AAAA,MAC1C;AAAA,IACJ,EAEC,OAAO,CAAC,iBAAiB,aAAa,SAAS,CAAC;AAGrD,UAAM,WAAW,uBACZ;AAAA,MACG,CAAC,iBACG,KAAK,aAAa,KAAK,IAAI,CAAC,oBAAoB,UAAU,kBAAkB,aAAa,CAAC,CAAE,CAAE,CAAC;AAAA,IACvG,EACC,KAAK,IAAI;AAEd,UAAM,IAAI;AAAA,MACN;AAAA;AAAA,EAA8D,QAAQ;AAAA;AAAA;AAAA,IAC1E;AAAA,EACJ;AACJ;;;AIrTA,SAAS,SAAS,oBAAoB;AACtC,SAAS,oBAAoB;AAC7B,SAAS,cAAc;AAEvB,SAAS,2BAA2B;AACpC,SAAS,oBAAsC;AAC/C,SAAS,kBAA4B;AACrC,SAAS,YAAY,aAAa,aAAa;AAK/C,IAAM,MAAiC;AAAA,EACnC,MAAM;AAAA,EACN,MAAM,MAAc,OAAe;AAC/B,WAAO,oBAAoB,KAAK;AAAA,EACpC;AAAA,EACA,WAAW;AAAA,EAAC;AAChB;AAEA,IAAM,gBAAgB,CAAC,UAAwC,OAAO,OAAe,WAAW,EAAE,SAAS,KAAK;AAOhH,IAAM,cAA4C;AAAA,EAC9C,MAAM;AAAA,EACN,MAAM,MAAc,OAAe;AAC/B,QAAI,CAAC,cAAc,KAAK,GAAG;AACvB,YAAM,IAAI,aAAa,OAAO,UAAU,wBAAwB;AAAA,QAC5D;AAAA,QACA;AAAA,QACA,MAAM;AAAA,MACV,CAAC;AAAA,IACL;AAEA,WAAO;AAAA,EACX;AAAA,EACA,WAAW;AAAA,EAAC;AAChB;AAEA,IAAM,UAAU,CAAC,UAAkC,OAAO,OAAe,KAAK,EAAE,SAAS,KAAK;AAO9F,IAAM,QAAgC;AAAA,EAClC,MAAM;AAAA,EACN,MAAM,MAAc,OAAe;AAC/B,QAAI,CAAC,QAAQ,KAAK,GAAG;AACjB,YAAM,IAAI,aAAa,OAAO,UAAU,wBAAwB;AAAA,QAC5D;AAAA,QACA;AAAA,QACA,MAAM;AAAA,MACV,CAAC;AAAA,IACL;AAEA,WAAO;AAAA,EACX;AAAA,EACA,WAAW;AAAA,EAAC;AAChB;AAOA,IAAM,MAAmC;AAAA,EACrC,MAAM;AAAA,EACN,MAAM,MAAc,OAAe;AAC/B,UAAM,aAAa,SAAS,KAAK;AACjC,QAAI,MAAM,UAAU,GAAG;AACnB,YAAMA,OAAM,WAAW,KAAK;AAE5B,UAAI,OAAOA,SAAQ,UAAU;AACzB,cAAM,IAAI,aAAa,OAAO,UAAU,wBAAwB;AAAA,UAC5D;AAAA,UACA;AAAA,UACA,MAAM;AAAA,QACV,CAAC;AAAA,MACL;AAEA,aAAOA;AAAA,IACX;AAEA,UAAM,WAAW,WAAW,UAAU;AACtC,QAAI,OAAO,aAAa,UAAU;AAC9B,YAAM,IAAI,aAAa,OAAO,UAAU,wBAAwB;AAAA,QAC5D;AAAA,QACA;AAAA,QACA,MAAM;AAAA,MACV,CAAC;AAAA,IACL;AAEA,WAAO;AAAA,EACX;AAAA,EACA,WAAW;AAAA,EAAC;AAChB;AAOA,IAAM,WAAsC;AAAA,EACxC,MAAM;AAAA,EACN,MAAM,MAAc,OAAe;AAC/B,QAAI,CAAC,WAAW,KAAK,GAAG;AACpB,YAAM,IAAI,aAAa,OAAO,UAAU,wBAAwB;AAAA,QAC5D;AAAA,QACA;AAAA,QACA,MAAM;AAAA,MACV,CAAC;AAAA,IACL;AAEA,WAAO;AAAA,EACX;AAAA,EACA,WAAW;AAAA,EAAC;AAChB;AAQO,IAAM,KAA8B;AAAA,EACvC,MAAM;AAAA,EACN,OAAO,CAAC,SAAS,UAAU;AACvB,QAAI,OAAO,UAAU,YAAY;AAC7B,YAAM,IAAI,aAAa,OAAO,UAAU,wBAAwB;AAAA,QAC5D;AAAA,QACA,MAAM;AAAA,QACN,MAAM,GAAG;AAAA,MACb,CAAC;AAAA,IACL;AAEA,WAAO;AAAA,EACX;AAAA,EACA,WAAW;AAAA,EAAC;AAChB;AAMO,IAAM,SAA4C;AAAA,EACrD,MAAM;AAAA,EACN,OAAO,CAAC,SAAS,UAAU;AAEvB,QAAI,aAAa,KAAK,GAAG;AACrB,aAAO,EAAE,MAAM,WAAW,SAAS,MAAM;AAAA,IAC7C;AAGA,UAAM,SAAS,SAAS,OAAO,EAAE;AACjC,QAAI,CAAC,MAAM,MAAM,GAAG;AAChB,UAAI,SAAS,GAAG;AACZ,cAAM,IAAI,aAAa,OAAO,UAAU,wBAAwB;AAAA,UAC5D;AAAA,UACA,MAAM;AAAA,UACN,MAAM,OAAO;AAAA,QACjB,CAAC;AAAA,MACL;AAEA,aAAO,EAAE,MAAM,SAAS,OAAO,OAAO;AAAA,IAC1C;AAGA,WAAO,EAAE,MAAM,SAAS,MAAM,MAAM;AAAA,EACxC;AAAA,EACA,WAAW;AAAA,EAAC;AAChB;AAEO,IAAM,QAAQ,EAAE,KAAK,KAAK,UAAU,IAAI,QAAQ,aAAa,OAAO,GAAG,aAAa;;;ANhK3F,SAAS,qBAAqB;;;AOjB9B,OAAO,UAAU,sBAAsB;AACvC,OAAO;AAaA,SAAS,oBACZ,KACuD;AACvD,SAAO,IAAI,aAAa,2DAA2D;AACvF;AASO,SAAS,sBACZ,cACA,MAAiC,6BAA6B,GACjD;AACb,QAAM,sBAAsB,IAAI,IAAI,OAAO,KAAK,qBAAqB,GAAG,CAAC,CAAC;AAE1E,aAAW,eAAe,cAAc;AACpC,QAAI,oBAAoB,IAAI,WAAW,GAAG;AACtC;AAAA,IACJ;AAEA,UAAM,IAAI,eAAe;AAAA,MACrB,SAAS,YAAY,WAAW,gDAAgD,MAAM,KAAK,mBAAmB,EAAE,KAAK,IAAI,CAAC;AAAA,IAC9H,CAAC;AAAA,EACL;AAEA,SAAO;AACX;;;APxBA,SAAS,uBAAAC,4BAA2B;AACpC,SAAS,mBAAmB;AAC5B,SAAgB,yBAAyB;AAqCzC,IAAM,SAA+B,OACjC,EAAE,UAAU,kBAAkB,MAAM,eAAe,CAAC,GAAG,UAAAC,YAAW,QAAQ,KAAK,OAAO,QAAQ,OAAO,OAAAC,OAAM,GAC3G,QACyB;AACzB,YAAU;AAGV,wBAAsB,8CAAoB,CAAC,CAAC;AAG5C,qBAAmBD,SAAQ;AAG3B,QAAME,UAAS,aAAa;AAG5B,QAAM,gBAAgB,CAAC;AACvB,EAAAA,QAAO,MAAM,gBAAgB,gCAAgC,sCAAsC;AACnG,EAAAA,QAAO,MAAM,QAAQ,qCAAqC,sCAAsC;AAGhG,MAAI;AACA,IAAAA,QAAO,KAAK,gCAAgC;AAE5C,UAAM,IAAI,IAAI,YAAY;AAAA,EAC9B,SAAS,OAAO;AACZ,IAAAA,QAAO,KAAK,kCAAkC,KAAK,EAAE;AAAA,EACzD;AAGA,MAAI,oBAAoB,QAAQD,UAAS,MAAM;AAC3C,IAAAC,QAAO,MAAM,WAAWD,MAAK,kDAAkD,iBAAiB,KAAK,GAAG,CAAC,EAAE;AAE3G,YAAQ,KAAK,CAAC;AAAA,EAClB;AAGA,QAAM,iBAAiB,OAAO,QAAQ,qBAAqB,CAAC;AAE5D,QAAM,yBACFA,UAAS,OACH,iBACA,eAAe,OAAO,CAAC,CAAC,EAAEH,IAAG,MAAMA,QAAO,QAAQ,kBAAkBA,IAAG,MAAMG,MAAK;AAC5F,QAAM,yBAAyB,uBAAuB,QAAQ,CAAC,CAAC,MAAMH,IAAG,MAAOA,QAAO,OAAO,CAAC,IAAI,CAAC,IAAI,CAAE;AAG1G,QAAM,WAAqB,8CAAoB;AAG/C,MAAI;AAEJ,MAAI;AAEJ,MAAI,eAAe;AAIf,UAAM,cAAc,IAAI,IAAI,QAAQ;AAEpC,UAAM,UAAkC,eACnC,IAAI,CAAC,CAAC,aAAaA,IAAG,OAAO;AAAA,MAC1B,OAAO;AAAA,MACP,OAAO;AAAA,MACP,UAAUA,QAAO;AAAA,MACjB,UAAU,YAAY,IAAI,WAAW;AAAA,MACrC,MAAMA,QAAO,OAAO,SAAY,gBAAgBJ,WAAUI,IAAG,CAAC;AAAA,IAClE,EAAE,EACD;AAAA,MACG,CAAC,GAAG;AAAA;AAAA,QAEA,OAAO,EAAE,QAAQ,IAAI,OAAO,EAAE,QAAQ;AAAA,QAEtC,EAAE,MAAM,cAAc,EAAE,KAAK;AAAA;AAAA,IACrC;AAGJ,uBAAmB,MAAM,uBAAuB,4CAA4C,EAAE,QAAQ,CAAC;AAGvG,mBAAe,MAAM,cAAc,mDAAmD;AAAA,MAClF,cAAc,6CAAc,KAAK;AAAA,MACjC,MAAM;AAAA,IACV,CAAC,EAAE,KAAKC,oBAAmB;AAAA,EAC/B,OAAO;AAEH,uBAAmB;AACnB,mBAAe;AAAA,EACnB;AAGA,MAAI,iBAAiB,WAAW,GAAG;AAC/B,WAAOG,QAAO,KAAK,+BAA+B,GAAG,CAAC;AAAA,EAC1D;AAGA,EAAAA,QAAO;AAAA,IACH;AAAA,MACI,iBAAiB;AAAA,MACjB,0BAA0B,iBAAiB,KAAK,GAAG,CAAC;AAAA,MACpD,eAAe,iBAAiB,MAAM,cAAc,iBAAiB,KAAK,IAAI,CAAC;AAAA,IACnF;AAAA,EACJ;AAEA,MAAI,aAAa,WAAW,GAAG;AAE3B,IAAAA,QAAO,KAAK,iCAAiC;AAAA,EACjD,OAAO;AACH,IAAAA,QAAO,KAAK,uCAAuC,aAAa,KAAK,IAAI,CAAC,EAAE;AAAA,EAChF;AAGA,QAAM,eAAe,gBAAgB,MAAM,iBAAiB,IAAI;AAChE,MAAI,CAAC,cAAc;AACf,WAAOA,QAAO,QAAQ,uCAAuC,GAAG,CAAC;AAAA,EACrE;AAGA,EAAAA,QAAO,QAAQ,4BAA4B;AAG3C,QAAM,cAAc,OAAO,kBAAkB,EAAE,QAAQ,iBAAiB,OAAO,MAAM,iBAAiB,MAAM,GAAG,CAAC,CAAC;AAKjH,MAAI,eAAuB;AAG3B,QAAM,UAAyB,CAAC;AAGhC,QAAM,QAAQ;AAAA,IACV,iBAAiB,IAAI,OAAO,gBAAgB;AAExC,YAAM,MAAM,MAAM,oBAAoB,WAAW;AAEjD,UAAI;AAEA,4BAAoB,GAAG;AAUvB,cAAM,oBAAoB,MAAM,IAAI,YAAY,IAAI;AAGpD,cAAM,mBAAmB,MAAM,IAAI,YAAY,IAAI,cAAc;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,UAM7D,aAAa;AAAA,UACb,yBAAyB;AAAA,UACzB,2BAA2B;AAAA,QAC/B,CAAC;AAGD,cAAM,YAAY,OAAO;AAAA,UACrB,OAAO,QAAQ,gBAAgB,EAAE;AAAA,YAC7B,CAAC,CAAC,IAAI,MAAM,CAAC,YAAY,kBAAkB,IAAI,GAAG,iBAAiB,IAAI,CAAC;AAAA,UAC5E;AAAA,QACJ;AAEA,gBAAQ,WAAW,IAAI,EAAE,UAAU;AAEnC,QAAAA,QAAO,MAAM,iCAAiC,WAAW,EAAE;AAAA,MAC/D,SAAS,OAAgB;AAKrB,gBAAQ,WAAW,IAAI,EAAE,MAAM;AAE/B,QAAAA,QAAO,MAAM,4BAA4B,WAAW,KAAK,KAAK,EAAE;AAAA,MACpE,UAAE;AACE;AAGA,oBAAY;AAAA,UACR,kBAAkB;AAAA,YACd,QAAQ;AAAA,YACR,OAAO,IAAI,YAAY,IAAI,iBAAiB,MAAM;AAAA,YAClD,UAAU,eAAe,iBAAiB;AAAA,UAC9C,CAAC;AAAA,QACL;AAAA,MACJ;AAAA,IACJ,CAAC;AAAA,EACL;AAGA,cAAY,MAAM;AAGlB,QAAM,SAAS,OAAO,QAAQ,OAAO,EAAE;AAAA,IAAQ,CAAC,CAAC,aAAa,EAAE,MAAM,CAAC,MACnE,SAAS,OAAO,CAAC,IAAI,CAAC,EAAE,aAAa,MAAM,CAAC;AAAA,EAChD;AAGA,MAAI,OAAO,WAAW,GAAG;AACrB,WAAOA,QAAO,KAAK,GAAG,aAAa,IAAI,CAAC,kCAAkC,GAAG;AAAA,EACjF;AAGA,EAAAA,QAAO;AAAA,IACH,GAAG,aAAa,KAAK,CAAC,IAAI,cAAc,OAAO,QAAQ,8BAA8B,oBAAoB,OAAO,MAAM,WAAW,CAAC;AAAA,EACtI;AAGA,QAAM,gBAAgB,gBAAgB,MAAM,iBAAiB,8CAA8C,IAAI;AAC/G,MAAI,eAAe;AACf;AAAA,MACI,OAAO,IAAI,CAAC,EAAE,aAAa,MAAM,OAAO;AAAA,QACpC,SAAS;AAAA,QACT,OAAO,OAAO,KAAK;AAAA,MACvB,EAAE;AAAA,IACN;AAAA,EACJ;AAGA,UAAQ,WAAW,QAAQ,YAAY;AAEvC,SAAO;AACX;AAEAT,MAAK,gBAAgB,8BAA8B,MAAM,EACpD;AAAA,EACG;AAAA,EACA;AAAA,EACA;AAAA,EACA,MAAM;AAAA,EACN;AACJ,EACC;AAAA,EACG;AAAA,EACA;AAAA,EACA;AAAA,EACA,MAAM;AAAA,EACN;AACJ,EACC,SAAS,YAAY,mEAAmE,QAAQ,MAAM,QAAQ,EAC9G,SAAS,SAAS,kDAAkD,QAAW,MAAM,OAAO,IAAI,EAChG,QAAQ,MAAM,yFAAyF,EACvG,QAAQ,SAAS,6BAA6B;;;AQpTnD,OAAO;;;ACIP,SAAS,QAAAA,aAAY;AACrB,SAAS,aAAAU,kBAAiB;AAC1B,SAAmB,gBAAAC,eAAc,QAAQ,WAAW,sBAAAC,2BAA0B;;;ACJ9E,SAAS,eAAe;AAExB,SAAS,YAAY;AACrB,YAAY,OAAO;AASZ,IAAM,0BAA0B,CACnC,YACA,kBACgB;AAjBpB;AAiBwB;AAAA,IACpB,OAAM,gBAAW,SAAX,YAAmB;AAAA,IACzB,WAAW,QAAQ,cAAc,MAAM,OAAM,gBAAW,cAAX,YAAwB,YAAY;AAAA,IACjF,oBAAmB,gBAAW,sBAAX,YAAgC;AAAA,IACnD,OAAO;AAAA;AAAA,MAEH,UAAU;AAAA,MACV,GAAG,WAAW;AAAA;AAAA;AAAA,MAGd,MAAM;AAAA,MACN,MAAM;AAAA,IACV;AAAA,EACJ;AAAA;AAgBO,IAAM,qCAAqC,CAC9C,QACA,mBAEA;AAAA,EACI;AAAA;AAAA,EAEE,SAAO,mBAAmB;AAAA;AAAA,EAE1B;AAAA,IACE,CAAC,mBAAoD;AAAA,MACjD,GAAG,OAAO;AAAA,MACV,SAAS,cAAc;AAAA,IAC3B;AAAA,EACJ;AACJ;AAyDG,IAAM,qBAAqB,CAAC,aAC7B,kBAAuC,CAAC,gBAAwB,SAAS,SAAS,WAAW,CAAC;AAQpG,IAAM,sBAAsB,CAAC,kBACzB,SAAS,iBAAiB,OAAO,cAAc,QAAQ;;;ADvH3D,SAAS,YAAY;AACrB,SAAS,iBAAiB;AAO1B,IAAMC,UAA6C,OAAO,EAAE,UAAAN,YAAW,QAAQ,SAAS,MAAM,GAAG,QAAQ;AAjBzG;AAkBI,EAAAK,oBAAmBL,SAAQ;AAE3B,EAAAG,WAAU;AAEV,QAAMD,UAASE,cAAa;AAG5B,QAAM,wBAAuB,qBAAI,WAAW,cAAf,mBAA0B,iBAA1B,mBAAwC,eAAxC,YAAsD,CAAC;AACpF,EAAAF,QAAO,QAAQ;AAAA,EAAkC,UAAU,oBAAoB,CAAC,EAAE;AAGlF,QAAM,mBAAmB,wBAAwB,sBAAsB,IAAI,MAAM;AACjF,EAAAA,QAAO,QAAQ;AAAA,EAAgC,UAAU,gBAAgB,CAAC,EAAE;AAG5E,QAAM,oBAAoB,KAAK,iBAAiB,WAAW,qBAAqB;AAChF,MAAI,CAAC,OAAO,iBAAiB,GAAG;AAC5B,IAAAA,QAAO,KAAK,kDAAkD,iBAAiB,GAAG;AAClF,IAAAA,QAAO,KAAK,4BAA4B,6BAA6B,IAAI;AAEzE,YAAQ,WAAW;AAEnB;AAAA,EACJ;AAMA,MAAI;AACA,IAAAA,QAAO,QAAQ,4CAA4C,iBAAiB,EAAE;AAE9E,UAAM,UAAU,CAAC,WAAW,MAAM,mBAAmB,QAAQ,GAAI,SAAS,CAAC,UAAU,IAAI,CAAC,CAAE;AAE5F,cAAU,UAAU,SAAS,EAAE,OAAO,UAAU,CAAC;AAAA,EACrD,SAAS,OAAO;AACZ,IAAAA,QAAO,MAAM,mDAAmD,iBAAiB,KAAK,KAAK,EAAE;AAE7F,YAAQ,WAAW;AAEnB;AAAA,EACJ;AACJ;AAEA,IAAI,QAAQ,IAAI,mCAAmC;AAC/C,EAAAT,MAAK,8BAA8B,gDAAgDa,OAAM,EACpF,SAAS,YAAY,mEAAmE,QAAQ,MAAM,QAAQ,EAC9G,QAAQ,UAAU,mBAAmB;AAC9C;;;AE9DA,SAAS,QAAAb,aAAY;AAErB,SAAS,aAAAU,kBAAiB;AAC1B,SAAmB,gBAAAC,eAAc,aAAAG,YAAW,sBAAAF,2BAA0B;AACtE,SAAS,WAAW,qBAAqB;AACzC,SAAS,QAAAG,aAAY;AACrB,SAAS,kCAAkC;;;ACV3C,SAAS,QAAAC,aAAY;AACrB,YAAY,QAAQ;AAEpB,SAA4B,6BAA6B;AAUlD,IAAM,2BAA2B,CAAC,kBAAoD;AAAA;AAAA;AAAA;AAAA;AAAA,EAKzF,OAAO;AAAA,IACH,YAAY;AAAA,IACZ,QAAQ;AAAA,EACZ;AAAA,EACA,SAAS,CAAC,SAAS,GAAG,sBAAsB,YAAY,CAAC;AAC7D;AAUO,IAAM,gCAAgC,CACzC,MACA,qBACsB;AAAA;AAAA;AAAA;AAAA;AAAA,EAKtB,OAAO;AAAA,IACH,YAAY;AAAA,IACZ,QAAQ;AAAA,EACZ;AAAA;AAAA;AAAA;AAAA;AAAA,EAKA,OAAO,CAAC,GAAG,IAAI,OAAO;AAAA,EACtB,YAAYA;AAAA,IACR;AAAA;AAAA;AAAA;AAAA,IAIG,OAAI,OAAO;AAAA,MACV,WAAW;AAAA,IACf,EAAE;AAAA,EACN;AACJ;AAUO,IAAM,8BAA8B,CACvC,QACA,cACe;AAAA,EACf,UAAUA;AAAA,IACN;AAAA;AAAA,IAEG,OAAI,wBAAwB;AAAA,IAC/B,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MASGA;AAAA,QACI;AAAA,QACG,YAAS,OAAO,8BAA8B,OAAO,MAAM,mBAAmB,CAAC;AAAA,MACtF;AAAA;AAAA,EACR;AACJ;;;AC3FA;;;ACAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;;AHgBA,SAAS,aAAAC,kBAAiB;AAC1B,SAA4B,qBAAAC,0BAAyB;AASrD,IAAML,UAA8C,OAChD,EAAE,UAAU,kBAAkB,SAAS,OAAO,UAAAN,YAAW,QAAQ,OAAAC,OAAM,GACvE,QACC;AA7BL;AA8BI,EAAAI,oBAAmBL,SAAQ;AAE3B,EAAAG,WAAU;AAEV,QAAMD,UAASE,cAAa;AAG5B,MAAI,oBAAoB,QAAQH,UAAS,MAAM;AAC3C,IAAAC,QAAO,MAAM,WAAWD,MAAK,kDAAkD,iBAAiB,KAAK,GAAG,CAAC,EAAE;AAE3G,YAAQ,KAAK,CAAC;AAAA,EAClB;AAGA,QAAM,YAAYA,UAAS,OAAO,MAAM,OAAO,CAACH,SAAoBa,mBAAkBb,IAAG,MAAMG;AAG/F,QAAM,WAAW;AAAA;AAAA,IAEX,sBAAsB,gBAAgB;AAAA;AAAA;AAAA,IAEtC,OAAO,QAAQ,qBAAqB,CAAC,EAAE;AAAA,MAAQ,CAAC,CAAC,aAAaH,IAAG,MAC7DA,QAAO,QAAQ,UAAUA,IAAG,IAAI,CAAC,WAAW,IAAI,CAAC;AAAA,IACrD;AAAA;AAMN,MAAI,SAAS,WAAW,GAAG;AACvB,IAAAI,QAAO,KAAK,0CAA0C;AAEtD;AAAA,EACJ;AAEA,EAAAA,QAAO,KAAK,uDAAuD,SAAS,KAAK,IAAI,CAAC,EAAE;AAGxF,QAAM,wBAAuB,qBAAI,WAAW,cAAf,mBAA0B,iBAA1B,mBAAwC,eAAxC,YAAsD,CAAC;AACpF,EAAAA,QAAO,QAAQ;AAAA,EAAkCK,WAAU,oBAAoB,CAAC,EAAE;AAGlF,QAAM,mBAAmB,wBAAwB,sBAAsB,IAAI,MAAM;AACjF,EAAAL,QAAO,QAAQ;AAAA,EAAgCK,WAAU,gBAAgB,CAAC,EAAE;AAG5E,QAAM,iBAAiB,mBAAmB,QAAQ,EAAE,IAAI,OAAO,QAAQ;AAGvE,QAAM,eAAe,mCAAmC,kBAAkB,cAAc;AACxF,EAAAL,QAAO,QAAQ;AAAA,EAAyBK,WAAU,YAAY,CAAC,EAAE;AAGjE,QAAM,cAAc,4BAA4B,kBAAkB,YAAY;AAC9E,QAAM,wBAAwB,2BAA2B,WAAW;AAGpE,EAAAL,QAAO,QAAQ,yBAAyB,iBAAiB,SAAS,SAAS;AAC3E,YAAU,iBAAiB,WAAW,EAAE,WAAW,KAAK,CAAC;AAEzD,QAAM,iBAAiBM,MAAK,iBAAiB,WAAW,YAAY;AACpE,EAAAN,QAAO,MAAM,oCAAoC,cAAc,EAAE;AACjE,gBAAc,gBAAgB,kBAAU;AAExC,QAAM,gBAAgBM,MAAK,iBAAiB,WAAW,YAAY;AACnE,EAAAN,QAAO,MAAM,kDAAkD,aAAa,EAAE;AAC9E,gBAAc,eAAe,aAAS;AAEtC,QAAM,oBAAoBM,MAAK,iBAAiB,WAAW,qBAAqB;AAChF,EAAAN,QAAO,MAAM,kDAAkD,iBAAiB,EAAE;AAClF,gBAAc,mBAAmB,qBAAqB;AAMtD,MAAI;AACA,QAAI,QAAQ;AACR,MAAAA,QAAO,KAAK,uCAAuC;AACnD,MAAAA,QAAO;AAAA,QACH,wDAAwD,4BAA4B;AAAA,MACxF;AAAA,IACJ,OAAO;AACH,MAAAA,QAAO,KAAK,qBAAqB;AAAA,IACrC;AAEA,IAAAA,QAAO,QAAQ,0CAA0C,iBAAiB,EAAE;AAG5E,UAAM,mBAA6B,SAAS,CAAC,QAAQ,IAAI,CAAC;AAE1D,UAAM,SAASQ,WAAU,UAAU,CAAC,WAAW,MAAM,mBAAmB,MAAM,GAAG,gBAAgB,GAAG;AAAA,MAChG,OAAO;AAAA,IACX,CAAC;AAED,QAAI,OAAO,WAAW,GAAG;AACrB,YAAM,IAAI,MAAM,mDAAmD,OAAO,MAAM,EAAE;AAAA,IACtF;AAAA,EACJ,SAAS,OAAO;AACZ,IAAAR,QAAO,MAAM,iDAAiD,iBAAiB,KAAK,KAAK,EAAE;AAE3F,YAAQ,WAAW;AAEnB;AAAA,EACJ;AACJ;AAEA,IAAI,QAAQ,IAAI,mCAAmC;AAC/C,EAAAT,MAAK,+BAA+B,yCAAyCa,OAAM,EAC9E,SAAS,YAAY,mEAAmE,QAAQ,MAAM,QAAQ,EAC9G,SAAS,YAAY,gDAAgD,QAAW,MAAM,KAAK,IAAI,EAC/F,SAAS,SAAS,kDAAkD,QAAW,MAAM,OAAO,IAAI,EAChG,QAAQ,UAAU,wCAAwC;AACnE;;;AI3IA,SAAS,QAAAb,aAAY;AACrB,SAAS,aAAAU,kBAAiB;AAC1B,SAAmB,gBAAAC,eAAc,UAAAQ,SAAQ,aAAAL,YAAW,sBAAAF,2BAA0B;AAG9E,SAAS,QAAAG,aAAY;AACrB,SAAS,aAAAE,kBAAiB;AAC1B,SAAS,cAAc;AAMvB,IAAMJ,UAA6C,OAAO,EAAE,UAAAN,YAAW,OAAO,GAAG,QAAQ;AAjBzF;AAkBI,EAAAK,oBAAmBL,SAAQ;AAE3B,EAAAG,WAAU;AAEV,QAAMD,UAASE,cAAa;AAG5B,QAAM,wBAAuB,qBAAI,WAAW,cAAf,mBAA0B,iBAA1B,mBAAwC,eAAxC,YAAsD,CAAC;AACpF,EAAAF,QAAO,QAAQ;AAAA,EAAkCK,WAAU,oBAAoB,CAAC,EAAE;AAGlF,QAAM,mBAAmB,wBAAwB,sBAAsB,IAAI,MAAM;AACjF,EAAAL,QAAO,QAAQ;AAAA,EAAgCK,WAAU,gBAAgB,CAAC,EAAE;AAG5E,QAAM,oBAAoBC,MAAK,iBAAiB,WAAW,qBAAqB;AAChF,MAAI,CAACI,QAAO,iBAAiB,GAAG;AAC5B,IAAAV,QAAO,KAAK,kDAAkD,iBAAiB,GAAG;AAClF,IAAAA,QAAO,KAAK,4BAA4B,6BAA6B,IAAI;AAEzE,YAAQ,WAAW;AAEnB;AAAA,EACJ;AAMA,MAAI;AACA,IAAAA,QAAO,KAAK,qBAAqB;AACjC,IAAAA,QAAO,QAAQ,4CAA4C,iBAAiB,EAAE;AAE9E,IAAAQ,WAAU,UAAU,CAAC,WAAW,MAAM,mBAAmB,MAAM,GAAG;AAAA,MAC9D,OAAO;AAAA,IACX,CAAC;AAAA,EACL,SAAS,OAAO;AACZ,IAAAR,QAAO,MAAM,mDAAmD,iBAAiB,KAAK,KAAK,EAAE;AAE7F,YAAQ,WAAW;AAEnB;AAAA,EACJ,UAAE;AACE,QAAI;AACA,aAAO,iBAAiB,WAAW,EAAE,OAAO,MAAM,WAAW,KAAK,CAAC;AAAA,IACvE,SAAS,OAAO;AACZ,MAAAA,QAAO,MAAM,qBAAqB,iBAAiB,SAAS,MAAM,KAAK,EAAE;AAAA,IAC7E;AAAA,EACJ;AACJ;AAEA,IAAI,QAAQ,IAAI,mCAAmC;AAC/C,EAAAT,MAAK,8BAA8B,uCAAuCa,OAAM,EAAE;AAAA,IAC9E;AAAA,IACA;AAAA,IACA;AAAA,IACA,MAAM;AAAA,EACV;AACJ;;;AC1EA,SAAS,6BAA2E;AAEpF,SAAS,WAAAO,gBAAe;AASxBA;AAAA,EACI;AAAA,EACA;AAAA,EACA,CAAC,EAAE,cAAc,GAAG,KAAK,MAA2B,sBAAsB,IAAI,EAAE,EAAE,aAAa,CAAC;AACpG,EACK,QAAQ,MAAM,yFAAyF,EACvG,SAAS,gBAAgB,mCAAmC,QAAW,MAAM,GAAG,EAChF,SAAS,gBAAgB,2DAA2D,QAAW,MAAM,EAAE,EACvG,SAAS,UAAU,iDAAiD,QAAW,MAAM,KAAK,IAAI,EAC9F,SAAS,aAAa,8CAA8C,QAAW,MAAM,IAAI,IAAI;;;ACtBlG,SAAS,QAAApB,aAAY;AAGrB,SAAqB,qBAAqB,UAAU,2BAA2B;AAC/E,SAAS,gBAAAW,eAAc,iBAAAU,gBAAe,gBAAAC,eAAc,sBAAAV,2BAA0B;AAE9E,SAAS,aAAAF,kBAAiB;AAU1B,IAAMG,UAA+B,OACjC,EAAE,UAAU,WAAW,UAAAN,YAAW,QAAQ,SAAS,YAAY,GAC/D,QACwB;AACxB,EAAAG,WAAU;AAGV,EAAAE,oBAAmBL,SAAQ;AAG3B,QAAME,UAASE,cAAa;AAG5B,QAAM,UAAU,SAAS;AAAA;AAAA,IAErB,gBAAgB,IAAI,OAAO,MAAM;AAAA,IACjC;AAAA,IACA,uBAAuB,oBAAoB,SAAS;AAAA,IACpD,mBAAmB,oBAAoB,QAAQ;AAAA,IAC/C,WAAW;AAAA,EACf,CAAC;AAED,EAAAF,QAAO;AAAA,IACH,GAAGa,cAAa,IAAI,CAAC,IAAID,eAAc,QAAQ,QAAQ,qBAAqB,aAAa,QAAQ,MAAM,QAAQ,CAAC;AAAA,EACpH;AAEA,aAAW,EAAE,KAAK,KAAK,SAAS;AAC5B,IAAAZ,QAAO,KAAK,IAAK,IAAI,EAAE;AAAA,EAC3B;AAEA,SAAO;AACX;AAEAT,MAAK,uCAAuC,0CAA0Ca,OAAM,EACvF;AAAA,EACG;AAAA,EACA;AAAA,EACA;AAAA,EACA,MAAM;AAAA,EACN;AACJ,EACC;AAAA,EACG;AAAA,EACA;AAAA,EACA;AAAA,EACA,MAAM;AAAA,EACN;AACJ,EACC,SAAS,YAAY,mEAAmE,QAAQ,MAAM,QAAQ;;;AC7DnH,SAAS,QAAAb,aAAY;AAErB,SAAS,gBAAAW,eAAc,gBAAAW,qBAAoB;AAC3C,SAAS,aAAAZ,kBAAiB;AAE1B,IAAM,kBAAkB;AAExB,IAAM,SAASC,cAAa;AAG5B,IAAM,qBAAqB,OAAO,WAAkC;AAChE,MAAI,CAAC,OAAO,aAAa;AACrB,WAAO,MAAM,GAAGW,cAAa,KAAK,CAAC,sBAAsB;AACzD,WAAO;AAAA,EACX;AAEA,MAAI,CAAC,OAAO,SAAS;AACjB,WAAO,MAAM,GAAGA,cAAa,KAAK,CAAC,kBAAkB;AACrD,WAAO;AAAA,EACX;AAGA,QAAM,SAAS,GAAG,OAAO,OAAO,iBAAiB,OAAO,WAAW;AAEnE,MAAI;AAEA,UAAM,WAAW,MAAM,MAAM,MAAM;AAGnC,QAAI,CAAC,SAAS,IAAI;AACd,aAAO;AAAA,IACX;AAEA,WAAO;AAAA,EACX,SAAS,OAAO;AACZ,QAAI,iBAAiB,OAAO;AACxB,aAAO,MAAM,sBAAsB,MAAM,OAAO,EAAE;AAAA,IACtD,OAAO;AAEH,aAAO,MAAM,2BAA2B;AAAA,IAC5C;AAEA,WAAO;AAAA,EACX;AACJ;AAEA,IAAMT,UAA8B,OAAO,GAAG,QAAQ;AAjDtD;AAkDI,EAAAH,WAAU;AAEV,QAAM,eAAe,OAAO,KAAK,IAAI,WAAW,YAAY,CAAC,CAAC;AAE9D,SAAO,KAAK,kCAAkC,aAAa,KAAK,IAAI,CAAC,KAAK;AAE1E,aAAW,eAAe,cAAc;AACpC,UAAM,iBAAgB,SAAI,WAAW,aAAf,mBAA0B;AAEhD,QAAI,iBAAiB,mBAAmB,eAAe;AACnD,YAAM,UAAU,MAAM,mBAAmB,cAAc,UAAU;AAEjE,UAAI,CAAC,SAAS;AACV,cAAM,IAAI,MAAM,GAAGY,cAAa,KAAK,CAAC,+CAA+C,WAAW,EAAE;AAAA,MACtG;AAAA,IACJ;AAAA,EACJ;AAEA,SAAO,KAAK,GAAGA,cAAa,IAAI,CAAC,8BAA8B;AACnE;AACAtB,MAAK,+BAA+B,8CAA8Ca,OAAM;;;ACnExF,SAAS,QAAAb,OAAM,SAAAuB,cAAa;AAE5B,SAAS,gBAAAZ,eAAc,gBAAAW,qBAAoB;AAE3C,SAAS,aAAAZ,kBAAiB;AAE1B,SAAuB,iBAAiB,yBAAyB;AAEjE,SAA4B,qBAAAQ,0BAAyB;AAGrD,IAAM,cAAc;AAEpB,IAAM,WAAW;AACjB,IAAM,YAAY;AAElB,IAAM,SAAS;AACf,IAAM,UAAU;AAEhB,IAAM,UAAU;AAEhB,IAAMT,UAASE,cAAa;AAQ5B,IAAM,cAAc,OAAO,QAAgB,gBAA+C;AACtF,MAAI;AACJ,MAAI,OAAO,WAAW,QAAQ,KAAK,OAAO,WAAW,SAAS,GAAG;AAC7D,eAAW,IAAI,gBAAgB,MAAM;AAAA,EACzC,WAAW,OAAO,WAAW,MAAM,KAAK,OAAO,WAAW,OAAO,GAAG;AAChE,eAAW,IAAI,kBAAkB,MAAM;AAAA,EAC3C,OAAO;AACH,IAAAF,QAAO,MAAM,wCAAwC,WAAW,EAAE;AAAA,EACtE;AAEA,SAAO;AACX;AAEA,IAAMI,UAAoC,OAAO,UAAU,QAAQ;AA7CnE;AA8CI,EAAAH,WAAU;AAGV,MAAI,SAAS,YAAY,QAAQ,SAAS,SAAS,MAAM;AACrD,IAAAD,QAAO;AAAA,MACH,WAAW,SAAS,KAAK,kDAAkD,SAAS,SAAS,KAAK,GAAG,CAAC;AAAA,IAC1G;AAEA,YAAQ,KAAK,CAAC;AAAA,EAClB;AAGA,QAAM,YACF,SAAS,SAAS,OAAO,MAAM,OAAO,CAACJ,SAAoBa,mBAAkBb,IAAG,MAAM,SAAS;AAGnG,QAAM,WAAW,SAAS;AAAA;AAAA,IAEpB,mBAAmB,sBAAsB,SAAS,QAAQ,CAAC,EAAE,IAAI,OAAO,QAAQ;AAAA,MAChF,SAAS,QACP;AAAA,IACI,OAAO,QAAQ,qBAAqB,CAAC,EAAE;AAAA,MAAQ,CAAC,CAAC,aAAaA,IAAG,MAC7DA,QAAO,QAAQ,UAAUA,IAAG,IAAI,CAAC,WAAW,IAAI,CAAC;AAAA,IACrD;AAAA,EACJ,EAAE,IAAI,OAAO,QAAQ,IACrB,IAAI,OAAO;AAEnB,QAAM,mBAAmB,qBAAqB,GAAG;AAEjD,EAAAI,QAAO;AAAA,IACH,kDAAgD,cAAS,aAAT,mBAAmB,KAAK,UAAS,OAAO,KAAK,gBAAgB,EAAE,KAAK,IAAI,CAAC;AAAA,EAC7H;AAEA,QAAM,0BAAoC,CAAC;AAE3C,QAAM,QAAQ;AAAA,IACV,OAAO,QAAQ,gBAAgB,EAAE,IAAI,OAAO,CAAC,aAAaJ,IAAG,MAAM;AAlF3E,UAAAmB;AAmFY,UAAI,CAACnB,MAAK;AACN,QAAAI,QAAO,KAAK,4BAA4B,WAAW,YAAY;AAC/D;AAAA,MACJ;AACA,YAAM,UAASe,MAAA,SAAS,WAAW,MAApB,gBAAAA,IAAwB;AACvC,UAAI,CAAC,QAAQ;AACT,QAAAf,QAAO,KAAK,gCAAgC,WAAW,YAAY;AACnE;AAAA,MACJ;AAEA,YAAM,WAAyB,MAAM,YAAY,QAAQ,WAAW;AACpE,UAAI,CAAC,UAAU;AACX,gCAAwB,KAAK,WAAW;AACxC,QAAAA,QAAO,MAAM,wCAAwC,WAAW,EAAE;AAClE;AAAA,MACJ;AAEA,aAAO,QAAQ,KAAK;AAAA,QAChB,SAAS,eAAe;AAAA,QACxB,IAAI,QAAc,CAAC,GAAG,WAAW,WAAW,QAAQ,SAAS,OAAO,CAAC;AAAA,MACzE,CAAC,EAAE;AAAA,QACC,CAAC,UAAU;AACP,iBAAO,CAAC,CAAC;AAAA,QACb;AAAA,QACA,MAAM;AACF,kCAAwB,KAAK,WAAW;AAAA,QAC5C;AAAA,MACJ;AAAA,IACJ,CAAC;AAAA,EACL;AAEA,MAAI,wBAAwB,WAAW,GAAG;AACtC,IAAAA,QAAO;AAAA,MACH,GAAGa,cAAa,KAAK,CAAC,yDAAyD,wBAAwB,KAAK,IAAI,CAAC;AAAA,IACrH;AAAA,EACJ,OAAO;AACH,IAAAb,QAAO,KAAK,GAAGa,cAAa,IAAI,CAAC,qCAAqC;AAAA,EAC1E;AACJ;AACAtB;AAAA,EACI;AAAA,EACA;AAAA,EACAa;AACJ,EACK;AAAA,EACG;AAAA,EACA,kHAAkH,OAAO;AAAA,EACzH;AAAA,EACAU,OAAM;AAAA,EACN;AACJ,EACC,SAAS,YAAY,gDAAgD,QAAW,MAAS,KAAK,IAAI,EAClG,SAAS,SAAS,kDAAkD,QAAW,MAAS,OAAO,IAAI","sourcesContent":["import { task } from 'hardhat/config'\nimport type { ActionType } from 'hardhat/types'\nimport { TASK_COMPILE } from 'hardhat/builtin-tasks/task-names'\nimport { TASK_LZ_DEPLOY } from '@/constants/tasks'\nimport {\n    PromptOption,\n    createLogger,\n    pluralizeNoun,\n    printBoolean,\n    promptToContinue,\n    promptToSelectMultiple,\n    setDefaultLogLevel,\n} from '@layerzerolabs/io-devtools'\n\nimport { createProgressBar, printLogo, printRecords, render } from '@layerzerolabs/io-devtools/swag'\nimport { formatEid } from '@layerzerolabs/devtools'\nimport { getEidsByNetworkName, getHreByNetworkName } from '@/runtime'\nimport { types } from '@/cli'\nimport { promptForText } from '@layerzerolabs/io-devtools'\nimport { Deployment } from 'hardhat-deploy/dist/types'\nimport { assertDefinedNetworks, assertHardhatDeploy } from '@/internal/assertions'\nimport { splitCommaSeparated } from '@layerzerolabs/devtools'\nimport { isDeepEqual } from '@layerzerolabs/devtools'\nimport { Stage, endpointIdToStage } from '@layerzerolabs/lz-definitions'\n\ninterface TaskArgs {\n    networks?: string[]\n    stage?: Stage\n    tags?: string[]\n    logLevel?: string\n    ci?: boolean\n    reset?: boolean\n}\n\n/**\n * Result of this task, a map of `NetworkDeployResult` objects keyed by network names\n *\n * @see {@link NetworkDeployResult}\n */\ntype DeployResults = Record<string, NetworkDeployResult>\n\n/**\n * Result of a deployment for one particular network.\n *\n * Unfortunately, when deployment fails partially,\n * there is now way of getting the partial deployment result from hardhat-deploy\n * and just an error is returned instead\n */\ntype NetworkDeployResult =\n    // A successful result will contain a map of deployments by their contract names\n    | {\n          contracts: Record<string, Deployment>\n          error?: never\n      }\n    // A failed result will only contain an error\n    | {\n          contracts?: never\n          error: unknown\n      }\n\nconst action: ActionType<TaskArgs> = async (\n    { networks: networksArgument, tags: tagsArgument = [], logLevel = 'info', ci = false, reset = false, stage },\n    hre\n): Promise<DeployResults> => {\n    printLogo()\n\n    // Make sure to check that the networks are defined\n    assertDefinedNetworks(networksArgument ?? [])\n\n    // We'll set the global logging level to get as much info as needed\n    setDefaultLogLevel(logLevel)\n\n    // And we'll create a logger for ourselves\n    const logger = createLogger()\n\n    // We only want to be asking users for input if we are not in interactive mode\n    const isInteractive = !ci\n    logger.debug(isInteractive ? 'Running in interactive mode' : 'Running in non-interactive (CI) mode')\n    logger.debug(reset ? 'Will delete existing deployments' : 'Will not delete existing deployments')\n\n    // The first thing to do is to ensure that the project is compiled\n    try {\n        logger.info(`Compiling your hardhat project`)\n\n        await hre.run(TASK_COMPILE)\n    } catch (error) {\n        logger.warn(`Failed to compile the project: ${error}`)\n    }\n\n    // --stage cannot be used in conjunction with --networks\n    if (networksArgument != null && stage != null) {\n        logger.error(`--stage ${stage} cannot be used in conjunction with --networks ${networksArgument.join(',')}`)\n\n        process.exit(1)\n    }\n\n    // We grab a mapping between network names and endpoint IDs\n    const eidsByNetworks = Object.entries(getEidsByNetworkName())\n    // If a stage argument is passed, we'll filter out the networks for that stage\n    const filteredEidsByNetworks =\n        stage == null\n            ? eidsByNetworks\n            : eidsByNetworks.filter(([, eid]) => eid != null && endpointIdToStage(eid) === stage)\n    const configuredNetworkNames = filteredEidsByNetworks.flatMap(([name, eid]) => (eid == null ? [] : [name]))\n\n    // We'll use all the configured network names as the default for the networks argument\n    const networks: string[] = networksArgument ?? configuredNetworkNames\n\n    // Here we'll store the final value for the networks we'd like to deploy\n    let selectedNetworks: string[]\n\n    let selectedTags: string[]\n\n    if (isInteractive) {\n        // In the interactive mode, we'll ask the user to confirm which networks they want to deploy\n\n        // We'll preselect the networks passed as --networks argument and we'll do it in O(1)\n        const networksSet = new Set(networks)\n\n        const options: PromptOption<string>[] = eidsByNetworks\n            .map(([networkName, eid]) => ({\n                title: networkName,\n                value: networkName,\n                disabled: eid == null,\n                selected: networksSet.has(networkName),\n                hint: eid == null ? undefined : `Connected to ${formatEid(eid)}`,\n            }))\n            .sort(\n                (a, b) =>\n                    // We want to show the enabled networks first\n                    Number(a.disabled) - Number(b.disabled) ||\n                    //  And sort the rest by their name\n                    a.title.localeCompare(b.title)\n            )\n\n        // Now we ask the user to confirm the network selection\n        selectedNetworks = await promptToSelectMultiple('Which networks would you like to deploy?', { options })\n\n        // And we ask to confirm the tags to deploy\n        selectedTags = await promptForText('Which deploy script tags would you like to use?', {\n            defaultValue: tagsArgument?.join(','),\n            hint: 'Leave empty to use all deploy scripts',\n        }).then(splitCommaSeparated)\n    } else {\n        // In the non-interactive mode we'll use whatever we got on the CLI\n        selectedNetworks = networks\n        selectedTags = tagsArgument\n    }\n\n    // If no networks have been selected, we exit\n    if (selectedNetworks.length === 0) {\n        return logger.warn(`No networks selected, exiting`), {}\n    }\n\n    // We'll tell the user what's about to happen\n    logger.info(\n        pluralizeNoun(\n            selectedNetworks.length,\n            `Will deploy 1 network: ${selectedNetworks.join(',')}`,\n            `Will deploy ${selectedNetworks.length} networks: ${selectedNetworks.join(', ')}`\n        )\n    )\n\n    if (selectedTags.length === 0) {\n        // Deploying all tags might not be what the user wants so we'll warn them about it\n        logger.warn(`Will use all deployment scripts`)\n    } else {\n        logger.info(`Will use deploy scripts tagged with ${selectedTags.join(', ')}`)\n    }\n\n    // Now we confirm with the user that they want to continue\n    const shouldDeploy = isInteractive ? await promptToContinue() : true\n    if (!shouldDeploy) {\n        return logger.verbose(`User cancelled the operation, exiting`), {}\n    }\n\n    // We talk we talk we talk\n    logger.verbose(`Running deployment scripts`)\n\n    // Now we render a progressbar to monitor the deployment progress\n    const progressBar = render(createProgressBar({ before: 'Deploying... ', after: ` 0/${selectedNetworks.length}` }))\n\n    // For now we'll use a very simple deployment logic with no retries\n    //\n    // For display purposes, we'll track the number of networks we deployed\n    let numProcessed: number = 0\n\n    // And for display purposes we'll also track the failures\n    const results: DeployResults = {}\n\n    // Now we run all the deployments\n    await Promise.all(\n        selectedNetworks.map(async (networkName) => {\n            // First we grab the hre for that network\n            const env = await getHreByNetworkName(networkName)\n\n            try {\n                // We need to make sure the user has enabled hardhat-deploy\n                assertHardhatDeploy(env)\n\n                // We first collect all existing deployments\n                //\n                // We do this so that we can diff the state before and after\n                // running the deployment scripts.\n                //\n                // This is, in immediate effect, a workaround for having to set resetMemory\n                // in the options for the run() function below to false. In near future though\n                // it opens doors for being able to return partially successful deployment results\n                const deploymentsBefore = await env.deployments.all()\n\n                // The core of this task, running the hardhat deploy scripts\n                const deploymentsAfter = await env.deployments.run(selectedTags, {\n                    // If we don't pass resetmemory or set it to true,\n                    // hardhat deploy will erase the database of deployments\n                    // (including the external deployments)\n                    //\n                    // In effect this means the deployments for LayerZero artifacts would not be available\n                    resetMemory: false,\n                    writeDeploymentsToFiles: true,\n                    deletePreviousDeployments: reset,\n                })\n\n                // Now we do a little diff on what contracts had been changed\n                const contracts = Object.fromEntries(\n                    Object.entries(deploymentsAfter).filter(\n                        ([name]) => !isDeepEqual(deploymentsBefore[name], deploymentsAfter[name])\n                    )\n                )\n\n                results[networkName] = { contracts }\n\n                logger.debug(`Successfully deployed network ${networkName}`)\n            } catch (error: unknown) {\n                // If we fail to deploy, we just store the error and continue\n                //\n                // Unfortunately, there is no way of knowing whether the failure was total\n                // or partial so we don't know whether there are any contracts that got deployed\n                results[networkName] = { error }\n\n                logger.debug(`Failed deploying network ${networkName}: ${error}`)\n            } finally {\n                numProcessed++\n\n                // Now we update the progressbar\n                progressBar.rerender(\n                    createProgressBar({\n                        before: 'Deploying... ',\n                        after: ` ${numProcessed}/${selectedNetworks.length}`,\n                        progress: numProcessed / selectedNetworks.length,\n                    })\n                )\n            }\n        })\n    )\n\n    // We drop the progressbar and continue\n    progressBar.clear()\n\n    // We check whether we got any errors\n    const errors = Object.entries(results).flatMap(([networkName, { error }]) =>\n        error == null ? [] : [{ networkName, error }]\n    )\n\n    // If nothing went wrong we just exit\n    if (errors.length === 0) {\n        return logger.info(`${printBoolean(true)} Your contracts are now deployed`), results\n    }\n\n    // We log the fact that there were some errors\n    logger.error(\n        `${printBoolean(false)} ${pluralizeNoun(errors.length, 'Failed to deploy 1 network', `Failed to deploy ${errors.length} networks`)}`\n    )\n\n    // If some of the deployments failed, we let the user know\n    const previewErrors = isInteractive ? await promptToContinue(`Would you like to see the deployment errors?`) : true\n    if (previewErrors) {\n        printRecords(\n            errors.map(({ networkName, error }) => ({\n                Network: networkName,\n                Error: String(error),\n            }))\n        )\n    }\n\n    // Mark the process as unsuccessful (only if it has not yet been marked as such)\n    process.exitCode = process.exitCode || 1\n\n    return results\n}\n\ntask(TASK_LZ_DEPLOY, 'Deploy LayerZero contracts', action)\n    .addParam(\n        'networks',\n        'List of comma-separated networks. If not provided, all networks will be deployed',\n        undefined,\n        types.csv,\n        true\n    )\n    .addParam(\n        'tags',\n        'List of comma-separated deploy script tags to deploy. If not provided, all deploy scripts will be executed',\n        undefined,\n        types.csv,\n        true\n    )\n    .addParam('logLevel', 'Logging level. One of: error, warn, info, verbose, debug, silly', 'info', types.logLevel)\n    .addParam('stage', 'Chain stage. One of: mainnet, testnet, sandbox', undefined, types.stage, true)\n    .addFlag('ci', 'Continuous integration (non-interactive) mode. Will not ask for any input from the user')\n    .addFlag('reset', 'Delete existing deployments')\n","export const TASK_LZ_DEPLOY = 'lz:deploy'\n\nexport const TASK_LZ_EXPORT_DEPLOYMENTS_TYPESCRIPT = 'lz:export:deployments:typescript'\n\nexport const SUBTASK_LZ_SIGN_AND_SEND = '::lz:sign-and-send'\n\nexport const TASK_LZ_TEST_SIMULATION_START = 'lz:test:simulation:start'\n\nexport const TASK_LZ_TEST_SIMULATION_LOGS = 'lz:test:simulation:logs'\n\nexport const TASK_LZ_TEST_SIMULATION_STOP = 'lz:test:simulation:stop'\n\nexport const TASK_LZ_VALIDATE_SAFE_CONFIGS = 'lz:healthcheck:validate:safe-configs'\n\nexport const TASK_LZ_VALIDATE_RPCS = 'lz:healthcheck:validate:rpcs'\n","import type {\n    HardhatRuntimeEnvironment,\n    EthereumProvider,\n    ConfigurableTaskDefinition,\n    HardhatArguments,\n} from 'hardhat/types'\n\nimport pMemoize from 'p-memoize'\nimport type { JsonRpcProvider } from '@ethersproject/providers'\nimport { ConfigurationError } from './errors'\nimport { HardhatContext } from 'hardhat/internal/context'\nimport { loadConfigAndTasks } from 'hardhat/internal/core/config/config-loading'\nimport { Environment as HardhatRuntimeEnvironmentImplementation } from 'hardhat/internal/core/runtime-environment'\nimport { EndpointId } from '@layerzerolabs/lz-definitions'\nimport { EndpointBasedFactory, Factory, formatEid } from '@layerzerolabs/devtools'\nimport { EthersProviderWrapper } from '@nomiclabs/hardhat-ethers/internal/ethers-provider-wrapper'\nimport assert from 'assert'\nimport memoize from 'micro-memoize'\nimport { subtask, task } from 'hardhat/config'\n\n/**\n * Helper type for when we need to grab something asynchronously by the network name\n */\nexport type GetByNetwork<TValue> = Factory<[networkName: string], TValue>\n\n/**\n * Helper type for when we need to grab something asynchronously by the network name\n */\nexport type GetByEid<TValue> = Factory<[eid: EndpointId], TValue>\n\n/**\n * Creates and sets the default hardhat context.\n *\n * This function will fail if a context has already been created\n */\nexport const createDefaultContext = (hardhatArguments: Partial<HardhatArguments> = {}) => {\n    const ctx = HardhatContext.createHardhatContext()\n    const resolvedArguments: HardhatArguments = {\n        showStackTraces: false,\n        version: false,\n        help: false,\n        emoji: false,\n        verbose: false,\n        ...hardhatArguments,\n    }\n    const { resolvedConfig, userConfig } = loadConfigAndTasks(resolvedArguments)\n    const envExtenders = ctx.environmentExtenders\n    const providerExtenders = ctx.providerExtenders\n    const taskDefinitions = ctx.tasksDSL.getTaskDefinitions()\n    const scopesDefinitions = ctx.tasksDSL.getScopesDefinitions()\n    const env = new HardhatRuntimeEnvironmentImplementation(\n        resolvedConfig,\n        resolvedArguments,\n        taskDefinitions,\n        scopesDefinitions,\n        envExtenders,\n        userConfig,\n        providerExtenders\n    )\n\n    ctx.setHardhatRuntimeEnvironment(env as unknown as HardhatRuntimeEnvironment)\n}\n\n/**\n * Returns the default hardhat context for the project, i.e.\n * the context that the project has been setup with.\n *\n * Throws if there is no context.\n *\n * @returns {HardhatContext}\n */\nexport const getDefaultContext = (): HardhatContext => {\n    // Context is registered globally as a singleton and can be accessed\n    // using the static methods of the HardhatContext class\n    //\n    // In our case we require the context to exist, the other option would be\n    // to create it and set it up - see packages/hardhat-core/src/register.ts for an example setup\n    try {\n        return HardhatContext.getHardhatContext()\n    } catch (error: unknown) {\n        throw new ConfigurationError(`Could not get Hardhat context: ${error}`)\n    }\n}\n\n/**\n * Returns the default `HardhatRuntimeEnvironment` (`hre`) for the project.\n *\n * Throws if there is no `HardhatRuntimeEnvironment`.\n *\n * @returns {HardhatRuntimeEnvironment}\n */\nexport const getDefaultRuntimeEnvironment = (): HardhatRuntimeEnvironment => {\n    // The first step is to get the hardhat context\n    const context = getDefaultContext()\n\n    // We require the hardhat environment to already exist\n    //\n    // Again, we could create it but that means we'd need to duplicate the bootstrap code\n    // that hardhat does when setting up the environment\n    try {\n        return context.getHardhatRuntimeEnvironment()\n    } catch (error: unknown) {\n        throw new ConfigurationError(`Could not get Hardhat Runtime Environment: ${error}`)\n    }\n}\n\n/**\n * Creates a clone of the HardhatRuntimeEnvironment for a particular network\n *\n * ```typescript\n * const env = getHreByNetworkName(\"bsc-testnet\");\n *\n * // All the ususal properties are present\n * env.deployments.get(\"MyContract\")\n * ```\n *\n * @returns {Promise<HardhatRuntimeEnvironment>}\n */\nexport const getHreByNetworkName: GetByNetwork<HardhatRuntimeEnvironment> = pMemoize(async (networkName) => {\n    const context = getDefaultContext()\n    const environment = getDefaultRuntimeEnvironment()\n\n    try {\n        // The last step is to create a duplicate environment that mimics the original one\n        // with one crucial difference - the network setup\n        return new HardhatRuntimeEnvironmentImplementation(\n            environment.config,\n            {\n                ...environment.hardhatArguments,\n                network: networkName,\n            },\n            environment.tasks,\n            environment.scopes,\n            context.environmentExtenders,\n            environment.userConfig,\n            context.providerExtenders\n            // This is a bit annoying - the environmentExtenders are not stronly typed\n            // so TypeScript complains that the properties required by HardhatRuntimeEnvironment\n            // are not present on HardhatRuntimeEnvironmentImplementation\n        ) as unknown as HardhatRuntimeEnvironment\n    } catch (error: unknown) {\n        throw new ConfigurationError(`Could not setup Hardhat Runtime Environment: ${error}`)\n    }\n})\n\n/**\n * Creates a clone of the HardhatRuntimeEnvironment for a particular network\n * identified by endpoint ID\n *\n * ```typescript\n * const getHreByEid = createGetHreByEid()\n * const env = await getHreByEid(EndpointId.AVALANCHE_V2_TESTNET);\n *\n * // All the ususal properties are present\n * env.deployments.get(\"MyContract\")\n * ```\n *\n * @returns {Promise<HardhatRuntimeEnvironment>}\n */\nexport const createGetHreByEid = (\n    hre = getDefaultRuntimeEnvironment()\n): EndpointBasedFactory<HardhatRuntimeEnvironment> =>\n    pMemoize(async (eid: EndpointId) => getHreByNetworkName(getNetworkNameForEid(eid, hre)))\n\n/**\n * Helper function that wraps an EthereumProvider with EthersProviderWrapper\n * so that we can use it further with ethers as a regular JsonRpcProvider\n *\n * @param {EIP1193Provider} provider\n * @returns {JsonRpcProvider}\n */\nexport const wrapEIP1193Provider = (provider: EthereumProvider): JsonRpcProvider => new EthersProviderWrapper(provider)\n\n/**\n * Gets an EndpointId defined in the hardhat config\n * for a particular network name (as an `eid` property).\n *\n * Throws if the network or the eid are not defined\n *\n * @param {string} networkName\n * @param {HardhatRuntimeEnvironment | undefined} [hre]\n * @returns {EndpointId}\n */\nexport const getEidForNetworkName = (\n    networkName: string,\n    hre: HardhatRuntimeEnvironment = getDefaultRuntimeEnvironment()\n): EndpointId => {\n    const networkConfig = hre.config.networks[networkName]\n    assert(networkConfig, `Network '${networkName}' is not defined in hardhat config`)\n    assert(networkConfig.eid != null, `Network '${networkName}' does not have 'eid' property defined in its config`)\n\n    return networkConfig.eid\n}\n\n/**\n * Gets a network name with its `eid` property matching\n * a particular `eid`\n *\n * Throws if there are multiple networks defined with the same `eid`.\n *\n * Returns `undefined` if there is no network with given `eid`\n *\n * @param {EndpointId} eid\n * @param {HardhatRuntimeEnvironment | undefined} [hre]\n * @returns {string | undefined}\n */\nexport const getNetworkNameForEidMaybe = (\n    eid: EndpointId,\n    hre: HardhatRuntimeEnvironment = getDefaultRuntimeEnvironment()\n): string | undefined => {\n    // We are using getEidsByNetworkName to get the nice validation of network config\n    const eidsByNetworkName = getEidsByNetworkName(hre)\n\n    for (const [networkName, networkEid] of Object.entries(eidsByNetworkName)) {\n        if (networkEid === eid) {\n            return networkName\n        }\n    }\n\n    return undefined\n}\n\n/**\n * Gets a network name with its `eid` property matching\n * a particular `eid`\n *\n * Throws if there is no such network or if there are multiple\n * networks defined with the same `eid`\n *\n * @param {EndpointId} eid\n * @param {HardhatRuntimeEnvironment | undefined} [hre]\n * @returns {string}\n */\nexport const getNetworkNameForEid = (\n    eid: EndpointId,\n    hre: HardhatRuntimeEnvironment = getDefaultRuntimeEnvironment()\n): string => {\n    const networkName = getNetworkNameForEidMaybe(eid, hre)\n\n    // Here we error out if there are no networks with this eid\n    return assert(networkName != null, `Could not find a network for eid ${eid} (${formatEid(eid)})`), networkName\n}\n\n/**\n * Gets a record containing the mapping between network names and endpoint IDs.\n * Will also return the network names for which the `eid` has not been defined\n *\n * Throws if there are multiple networks defined with the same `eid`\n *\n * @param {HardhatRuntimeEnvironment | undefined} [hre]\n * @returns {Record<string, EndpointId | undefined>}\n */\nexport const getEidsByNetworkName = memoize(\n    (hre: HardhatRuntimeEnvironment = getDefaultRuntimeEnvironment()): Record<string, EndpointId | undefined> => {\n        // First we get the network name -> network config pairs\n        const networkEntries = Object.entries(hre.config.networks)\n        // And map the network config to an endpoint ID\n        const eidEntries = networkEntries.map(\n            ([networkName, networkConfig]) => [networkName, networkConfig.eid] as const\n        )\n        // Now we turn the entries back into a record\n        const eidsByNetworkName = Object.fromEntries(eidEntries)\n\n        // Now we check that the user has not configured the endpoint ID mapping incorrectly\n        // (i.e. there are more networks configured with the same endpoint ID)\n        //\n        // For this we'll drop all the networks whose endpoint IDs are not defined\n        const eidEntriesWithDefinedEid = eidEntries.filter(([_, eid]) => eid != null)\n        const definedEidsByNetworkName = Object.fromEntries(eidEntriesWithDefinedEid)\n\n        // Now we grab the sets of unique network names and endpoint IDs\n        const allDefinedEids = new Set(Object.values(definedEidsByNetworkName))\n        const allNetworkNames = new Set(Object.keys(definedEidsByNetworkName))\n\n        // If the number of unique networks matches the number of unique endpoint IDs, there are no duplicates\n        if (allDefinedEids.size === allNetworkNames.size) {\n            return eidsByNetworkName\n        }\n\n        // At this point the number of defined endpoint IDs can only be lower than\n        // the number of defined network names (since network names are taken from the keys\n        // of an object and endpoint IDs from its values)\n        //\n        // To let the user know whihc networks to fix, we need to grab all the ones that\n        // have been duplicated\n        //\n        // We are not claiming any efficiency of this algorithm as we don't expect any large numbers of networks\n        const duplicatedNetworkNames = Array.from(allDefinedEids)\n            // First we grab all the network names with this endpoint ID\n            .map((eid) =>\n                eidEntriesWithDefinedEid.flatMap(([networkName, definedEid]) =>\n                    eid === definedEid ? [networkName] : []\n                )\n            )\n            // Then we find all the network names listed more than once\n            .filter((networkNames) => networkNames.length > 1)\n\n        // Now we let the user know which network names have identical endpoint IDs\n        const messages = duplicatedNetworkNames\n            .map(\n                (networkNames) =>\n                    `- ${networkNames.join(', ')} have eid set to ${formatEid(eidsByNetworkName[networkNames[0]!]!)}`\n            )\n            .join('\\n')\n\n        throw new Error(\n            `Found multiple networks configured with the same 'eid':\\n\\n${messages}\\n\\nPlease fix this in your hardhat config.`\n        )\n    }\n)\n\n/**\n * Helper utility that copies the whole task definition under a new name\n *\n * This is useful if a new task needs to have the same interface as an existing task,\n * for example if we want to create a slightly modified version of a wire task\n * without needing to retype all the `.addFlag` and `.addOption`\n *\n * @param {string} parentTaskName Task to inherit the options and the action from\n * @param {HardhatRuntimeEnvironment} [hre]\n * @returns {(taskName: string) => ConfigurableTaskDefinition}\n */\nexport const inheritTask =\n    (parentTaskName: string, context = getDefaultContext()) =>\n    (taskName: string): ConfigurableTaskDefinition => {\n        // For now we only support non-scoped tasks\n        const parentTaskDefinition = context.tasksDSL.getTaskDefinition(undefined, parentTaskName)\n        assert(parentTaskDefinition != null, `Missing task definition for ${parentTaskName}`)\n\n        // First we create the task definition itself\n        const creator = parentTaskDefinition.isSubtask ? subtask : task\n        const childTask = creator(taskName).setAction(parentTaskDefinition.action)\n\n        // Then we start setting properties\n        if (parentTaskDefinition.description != null) {\n            childTask.setDescription(parentTaskDefinition.description)\n        }\n\n        // Params go first (just because I said so, not for any particular reason)\n        for (const definition of Object.values(parentTaskDefinition.paramDefinitions)) {\n            // Params need to be treated based on their type (flag/param)\n            if (definition.isFlag) {\n                childTask.addFlag(definition.name, definition.description)\n            } else {\n                childTask.addParam(\n                    definition.name,\n                    definition.description,\n                    definition.defaultValue,\n                    definition.type,\n                    definition.isOptional\n                )\n            }\n        }\n\n        // Positional params go second\n        for (const definition of parentTaskDefinition.positionalParamDefinitions) {\n            if (definition.isVariadic) {\n                childTask.addVariadicPositionalParam(\n                    definition.name,\n                    definition.description,\n                    definition.defaultValue,\n                    definition.type,\n                    definition.isOptional\n                )\n            } else {\n                childTask.addPositionalParam(\n                    definition.name,\n                    definition.description,\n                    definition.defaultValue,\n                    definition.type,\n                    definition.isOptional\n                )\n            }\n        }\n\n        return childTask\n    }\n","'use strict'\n\nexport class ConfigurationError extends Error {}\n","import { getDefaultRuntimeEnvironment } from '@/runtime'\nimport { Artifacts } from 'hardhat/internal/artifacts'\nimport { Artifact } from 'hardhat/types'\nimport pMemoize from 'p-memoize'\n\n/**\n * Will return all artifacts available in the project, including the external ones\n *\n * @return {Promise<Artifact[]>}\n */\nexport const getAllArtifacts = pMemoize(async (hre = getDefaultRuntimeEnvironment()): Promise<Artifact[]> => {\n    // First we collect all the paths where artifacts could be\n    //\n    // This is a port of the code found in hardhat-deploy/src/DeploymentsManager.ts\n    const externalContracts = hre.config.external?.contracts ?? []\n    const artifactsPaths: string[] = [\n        hre.config.paths.artifacts,\n        hre.config.paths.imports,\n        ...externalContracts.flatMap(({ artifacts }) => artifacts),\n    ]\n\n    // Now we create Artifacts objects\n    const artifactsObjects = artifactsPaths.map((path) => new Artifacts(path))\n\n    // Oxford dictionary defines \"artifactses\" as the plural form of \"artifacts\"\n    const artifactses = await Promise.all(artifactsObjects.map(getAllArtifactsFrom))\n\n    return artifactses.flat()\n})\n\nconst getAllArtifactsFrom = async (artifactsObject: Artifacts) => {\n    // First we get all the fully qualified names fro mthis artifacts object\n    const fullyQualifiedNames = await artifactsObject.getAllFullyQualifiedNames()\n\n    return fullyQualifiedNames.map((name) => artifactsObject.readArtifactSync(name))\n}\n\nexport const isErrorFragment = <TFragment extends { type?: string }>(\n    fragment: TFragment\n): fragment is TFragment & { type: 'error' } => fragment.type === 'error'\n","import { getAllArtifacts, isErrorFragment } from '@/artifacts'\nimport { Contract } from '@ethersproject/contracts'\nimport { OmniContract, createContractErrorParser } from '@layerzerolabs/devtools-evm'\nimport { makeZeroAddress } from '@layerzerolabs/devtools-evm'\nimport { EndpointId } from '@layerzerolabs/lz-definitions'\nimport pMemoize from 'p-memoize'\n\n/**\n * Helper function that combines all the available ABIs into a one giant\n * interface (only containing the error fragments) used for error decoding.\n *\n * @returns {OmniContract}\n */\nconst createCombinedContract = pMemoize(async (): Promise<OmniContract> => {\n    // We get all the available artifacts first\n    const artifacts = await getAllArtifacts()\n\n    // Now we combine the ABIs and keep only the errors\n    const abi = artifacts.flatMap((artifact) => artifact.abi).filter(isErrorFragment)\n\n    // Even though duplicated fragments don't throw errors, they still pollute the interface with warning console.logs\n    // To prevent this, we'll run a simple deduplication algorithm - use JSON encoded values as hashes\n    const deduplicatedAbi = Object.values(Object.fromEntries(abi.map((abi) => [JSON.stringify(abi), abi])))\n\n    // FIXME Since we are creating an endpoint-agnostic, completely fictional contract,\n    // we just make up and eid for it. Once the underlying logic is refactored, this should be gone\n    return { eid: -1 as EndpointId, contract: new Contract(makeZeroAddress(), deduplicatedAbi) }\n})\n\n/**\n * Creates a generic error parser based on all the artifacts found in your hardhat project\n */\nexport const createErrorParser = async () => createContractErrorParser(await createCombinedContract())\n","import { types as builtInTypes } from 'hardhat/config'\nimport { HardhatError } from 'hardhat/internal/core/errors'\nimport { ERRORS } from 'hardhat/internal/core/errors-list'\nimport type { CLIArgumentType } from 'hardhat/types'\nimport { splitCommaSeparated } from '@layerzerolabs/devtools'\nimport { isEVMAddress, SignerDefinition } from '@layerzerolabs/devtools-evm'\nimport { isLogLevel, LogLevel } from '@layerzerolabs/io-devtools'\nimport { EndpointId, Environment, Stage } from '@layerzerolabs/lz-definitions'\n\n/**\n * Hardhat CLI type for a comma separated list of arbitrary strings\n */\nconst csv: CLIArgumentType<string[]> = {\n    name: 'csv',\n    parse(name: string, value: string) {\n        return splitCommaSeparated(value)\n    },\n    validate() {},\n}\n\nconst isEnvironment = (value: string): value is Environment => Object.values<string>(Environment).includes(value)\n\n/**\n * Hardhat CLI type for a LayzerZero chain environment\n *\n * @see {@link Environment}\n */\nconst environment: CLIArgumentType<Environment> = {\n    name: 'environment',\n    parse(name: string, value: string) {\n        if (!isEnvironment(value)) {\n            throw new HardhatError(ERRORS.ARGUMENTS.INVALID_VALUE_FOR_TYPE, {\n                value,\n                name: name,\n                type: 'environment',\n            })\n        }\n\n        return value\n    },\n    validate() {},\n}\n\nconst isStage = (value: string): value is Stage => Object.values<string>(Stage).includes(value)\n\n/**\n * Hardhat CLI type for a LayzerZero chain stage\n *\n * @see {@link Stage}\n */\nconst stage: CLIArgumentType<Stage> = {\n    name: 'stage',\n    parse(name: string, value: string) {\n        if (!isStage(value)) {\n            throw new HardhatError(ERRORS.ARGUMENTS.INVALID_VALUE_FOR_TYPE, {\n                value,\n                name: name,\n                type: 'stage',\n            })\n        }\n\n        return value\n    },\n    validate() {},\n}\n\n/**\n * Hardhat CLI type for a LayzerZero chain stage\n *\n * @see {@link Stage}\n */\nconst eid: CLIArgumentType<EndpointId> = {\n    name: 'eid',\n    parse(name: string, value: string) {\n        const valueAsInt = parseInt(value)\n        if (isNaN(valueAsInt)) {\n            const eid = EndpointId[value]\n\n            if (typeof eid !== 'number') {\n                throw new HardhatError(ERRORS.ARGUMENTS.INVALID_VALUE_FOR_TYPE, {\n                    value,\n                    name: name,\n                    type: 'stage',\n                })\n            }\n\n            return eid\n        }\n\n        const eidLabel = EndpointId[valueAsInt]\n        if (typeof eidLabel !== 'string') {\n            throw new HardhatError(ERRORS.ARGUMENTS.INVALID_VALUE_FOR_TYPE, {\n                value,\n                name: name,\n                type: 'stage',\n            })\n        }\n\n        return valueAsInt as EndpointId\n    },\n    validate() {},\n}\n\n/**\n * Hardhat CLI type for a log level argument\n *\n * @see {@link LogLevel}\n */\nconst logLevel: CLIArgumentType<LogLevel> = {\n    name: 'logLevel',\n    parse(name: string, value: string) {\n        if (!isLogLevel(value)) {\n            throw new HardhatError(ERRORS.ARGUMENTS.INVALID_VALUE_FOR_TYPE, {\n                value,\n                name: name,\n                type: 'logLevel',\n            })\n        }\n\n        return value\n    },\n    validate() {},\n}\n\n/**\n * Hardhat CLI type for a function argument.\n *\n * This is only to be used with subtasks since you cannot pass functions\n * to tasks (unless you're insane and want to inline a function)\n */\nexport const fn: CLIArgumentType<string> = {\n    name: 'function',\n    parse: (argName, value) => {\n        if (typeof value !== 'function') {\n            throw new HardhatError(ERRORS.ARGUMENTS.INVALID_VALUE_FOR_TYPE, {\n                value,\n                name: argName,\n                type: fn.name,\n            })\n        }\n\n        return value\n    },\n    validate() {},\n}\n\n/**\n * Signer-specific CLI argument (either a non-negative index\n * or a signer EVM address)\n */\nexport const signer: CLIArgumentType<SignerDefinition> = {\n    name: 'signer',\n    parse: (argName, value) => {\n        // If the value looks like an EVM address, we'll return an address definition\n        if (isEVMAddress(value)) {\n            return { type: 'address', address: value }\n        }\n\n        // If the value parses to an integer, we'll return an index definition\n        const parsed = parseInt(value, 10)\n        if (!isNaN(parsed)) {\n            if (parsed < 0) {\n                throw new HardhatError(ERRORS.ARGUMENTS.INVALID_VALUE_FOR_TYPE, {\n                    value,\n                    name: argName,\n                    type: signer.name,\n                })\n            }\n\n            return { type: 'index', index: parsed }\n        }\n\n        // In any other case we'll return a named definition\n        return { type: 'named', name: value }\n    },\n    validate() {},\n}\n\nexport const types = { csv, eid, logLevel, fn, signer, environment, stage, ...builtInTypes }\n","import { getDefaultRuntimeEnvironment, getEidsByNetworkName } from '@/runtime'\nimport assert, { AssertionError } from 'assert'\nimport 'hardhat-deploy/dist/src/type-extensions'\nimport { DeploymentsExtension } from 'hardhat-deploy/dist/types'\nimport { HardhatRuntimeEnvironment } from 'hardhat/types'\n\nexport interface HardhatRuntimeEnvironmentWithDeployments extends HardhatRuntimeEnvironment {\n    deployments: DeploymentsExtension\n}\n\n/**\n * Helper utility to make sure hardhat-deploy is being used by the project\n *\n * @param {HardhatRuntimeEnvironment} hre\n */\nexport function assertHardhatDeploy(\n    hre: HardhatRuntimeEnvironment\n): asserts hre is HardhatRuntimeEnvironmentWithDeployments {\n    assert(hre.deployments, `You don't seem to be using hardhat-deploy in your project`)\n}\n\n/**\n * Helper utility to make sure that all the networks passed\n * to this function have been defined in the config\n *\n * @param {Iterable<string>} networkNames\n * @param {HardhatRuntimeEnvironment} hre\n */\nexport function assertDefinedNetworks<TNetworkNames extends Iterable<string>>(\n    networkNames: TNetworkNames,\n    hre: HardhatRuntimeEnvironment = getDefaultRuntimeEnvironment()\n): TNetworkNames {\n    const definedNetworkNames = new Set(Object.keys(getEidsByNetworkName(hre)))\n\n    for (const networkName of networkNames) {\n        if (definedNetworkNames.has(networkName)) {\n            continue\n        }\n\n        throw new AssertionError({\n            message: `Network '${networkName}' has not been defined. Defined networks are ${Array.from(definedNetworkNames).join(', ')}`,\n        })\n    }\n\n    return networkNames\n}\n","import 'hardhat/types/config'\nimport { EndpointId } from '@layerzerolabs/lz-definitions'\nimport { ConnectSafeConfigWithSafeAddress } from '@safe-global/protocol-kit'\nimport { SimulationUserConfig } from '@/simulation/types'\n\n/**\n * Packages containing external artifacts can be specified either\n *\n * - By just their package name, in which case the artifacts will be loaded from the `./artifacts` path\n * - By their package name and a specific path to the artifacts directory\n * - By a filesystem path\n */\nexport type ArtifactPackage = ArtifactPackageName | ArtifactPackageWithPath | ArtifactPackagePath\n\nexport type ArtifactPackageName = string\n\nexport interface ArtifactPackageWithPath {\n    name: ArtifactPackageName\n    path?: string\n}\n\nexport interface ArtifactPackagePath {\n    name?: never\n    path: string\n}\n\ndeclare module 'hardhat/types/config' {\n    interface HardhatNetworkUserConfig {\n        eid?: never\n        safeConfig?: never\n    }\n\n    interface HardhatNetworkConfig {\n        eid?: never\n        safeConfig?: never\n    }\n\n    interface HttpNetworkUserConfig {\n        /**\n         * Specifies the mapping between the network\n         * defined in your hardhat config and the LayerZero endpoint ID\n         * on this network.\n         *\n         * This allows you to use arbitrary network names while maintaining\n         * allowing you to easily find deployment and artifact information\n         * for LayerZero protocol contracts using the standard hardhat deploy methods\n         */\n        eid?: EndpointId\n\n        /**\n         * Use a \"local\" LayerZero environment for the network.\n         *\n         * Local environments are postfixed with `-local` in the deployment directories\n         * and represent contracts deployed to ephemerous development networks.\n         *\n         * Local environments cannot coexists with their non-local counterparts\n         * in hardhat configs since they share the same `eid`\n         */\n        isLocalEid?: boolean\n\n        /**\n         * Optional gnosis safe config.\n         */\n        safeConfig?: SafeConfig\n    }\n\n    interface HttpNetworkConfig {\n        /**\n         * Specifies the mapping between the network\n         * defined in your hardhat config and the LayerZero endpoint ID\n         * on this network.\n         *\n         * This allows you to use arbitrary network names while maintaining\n         * allowing you to easily find deployment and artifact information\n         * for LayerZero protocol contracts using the standard hardhat deploy methods\n         */\n        eid?: EndpointId\n\n        /**\n         * Use a \"local\" LayerZero environment for the network.\n         *\n         * Local environments are postfixed with `-local` in the deployment directories\n         * and represent contracts deployed to ephemerous development networks\n         *\n         * Local environments cannot coexists with their non-local counterparts\n         * in hardhat configs since they share the same `eid`\n         */\n        isLocalEid?: boolean\n\n        /**\n         * Optional gnosis safe config.\n         */\n        safeConfig?: SafeConfig\n    }\n    interface SafeConfig extends ConnectSafeConfigWithSafeAddress {\n        safeUrl: string // Note:  This is the URL of the Safe API, not the safe itself\n        safeAddress: string // override to make ConnectSafeConfig.safeAddress mandatory\n    }\n\n    interface HardhatUserConfig {\n        /**\n         * LayerZero advanced configuration\n         */\n        layerZero?: LayerZeroHardhatUserConfig\n    }\n\n    interface LayerZeroHardhatUserConfig {\n        /**\n         * Defines the names of @layerzerolabs packages\n         * that will be added to your hardhat config under external deployments.\n         *\n         * By default, the protocol deployments from `@layerzerolabs/lz-evm-sdk-v2`\n         * will be added which allows your scripts to reference deployments\n         * of protocol contracts such as `EndpointV2`:\n         *\n         * ```\n         * // In your deploy script or task\n         * const { address, abi } = hre.deployments.get('EndpointV2')\n         * ```\n         *\n         * @default ['@layerzerolabs/lz-evm-sdk-v2']\n         */\n        deploymentSourcePackages?: string[]\n\n        /**\n         * Defines the names of @layerzerolabs packages\n         * that will be added to your hardhat config under external artifacts.\n         *\n         * By default, the protocol artifacts from `@layerzerolabs/lz-evm-sdk-v2`\n         * will be added which allows your scripts to reference artifacts\n         * of protocol contracts such as `EndpointV2`:\n         *\n         * ```\n         * // In your deploy script or task\n         * const { address, abi } = hre.deployments.get('EndpointV2')\n         * ```\n         *\n         * For testing purposes, artifacts from `@layerzerolabs/test-devtools-evm-hardhat`\n         * will also be added. This allows your tests to reference contracts such as `EndpointV2Mock`:\n         *\n         * ```\n         * // In your hardhat test\n         * const EndpointV2MockArtifact = await hre.deployments.getArtifact('EndpointV2Mock')\n         * ```\n         *\n         * @default ['@layerzerolabs/lz-evm-sdk-v2','@layerzerolabs/test-devtools-evm-hardhat']\n         */\n        artifactSourcePackages?: ArtifactPackage[]\n\n        /**\n         * Configuration of features that are not considered stable yet\n         */\n        experimental?: {\n            /**\n             * Configuration for omnichain simulation\n             *\n             * Omnichain simulation allows developers to easily setup\n             * local environment forked from live networks without\n             * having to adjust the `hardhat.config.ts` file\n             */\n            simulation?: SimulationUserConfig\n        }\n    }\n}\n","import '@/type-extensions'\n\nimport { TASK_LZ_TEST_SIMULATION_LOGS, TASK_LZ_TEST_SIMULATION_START } from '@/constants'\nimport { ActionType } from 'hardhat/types'\nimport { task } from 'hardhat/config'\nimport { printLogo } from '@layerzerolabs/io-devtools/swag'\nimport { LogLevel, createLogger, isFile, printJson, setDefaultLogLevel } from '@layerzerolabs/io-devtools'\nimport { types } from '@/cli'\nimport { resolveSimulationConfig } from '@/simulation/config'\nimport { join } from 'path'\nimport { spawnSync } from 'child_process'\n\nexport interface SimulationLogsTaskArgs {\n    logLevel?: LogLevel\n    follow?: boolean\n}\n\nconst action: ActionType<SimulationLogsTaskArgs> = async ({ logLevel = 'info', follow = false }, hre) => {\n    setDefaultLogLevel(logLevel)\n\n    printLogo()\n\n    const logger = createLogger()\n\n    // Grab the simulation user config from hardhat user config\n    const simulationUserConfig = hre.userConfig.layerZero?.experimental?.simulation ?? {}\n    logger.verbose(`Using simulation user config:\\n${printJson(simulationUserConfig)}`)\n\n    // Resolve the defaults for the simulation config\n    const simulationConfig = resolveSimulationConfig(simulationUserConfig, hre.config)\n    logger.verbose(`Resolved simulation config:\\n${printJson(simulationConfig)}`)\n\n    // Check that the docker compose file exists\n    const dockerComposePath = join(simulationConfig.directory, 'docker-compose.yaml')\n    if (!isFile(dockerComposePath)) {\n        logger.warn(`Could not find simulation docker compose file '${dockerComposePath}'`)\n        logger.warn(`Did you run 'npx hardhat ${TASK_LZ_TEST_SIMULATION_START}'?`)\n\n        process.exitCode = 1\n\n        return\n    }\n\n    // Spawn docker compose logs command, piping the stdout and stderr to the current shell\n    //\n    // The error reporting on this part should be improved - we should check that \"docker\" and \"docker compose\"\n    // are known commands before we go ahead and try executing them\n    try {\n        logger.verbose(`Spawning docker compose logs command for ${dockerComposePath}`)\n\n        const command = ['compose', '-f', dockerComposePath, 'logs', ...(follow ? ['--follow'] : [])]\n\n        spawnSync('docker', command, { stdio: 'inherit' })\n    } catch (error) {\n        logger.error(`Failed to spawn docker compose logs command for ${dockerComposePath}: ${error}`)\n\n        process.exitCode = 1\n\n        return\n    }\n}\n\nif (process.env.LZ_ENABLE_EXPERIMENTAL_SIMULATION) {\n    task(TASK_LZ_TEST_SIMULATION_LOGS, 'Show logs for LayerZero omnichain simulation', action)\n        .addParam('logLevel', 'Logging level. One of: error, warn, info, verbose, debug, silly', 'info', types.logLevel)\n        .addFlag('follow', 'Follow log output')\n}\n","import type { HardhatConfig, HttpNetworkConfig, NetworkConfig } from 'hardhat/types'\nimport type { SimulationConfig, SimulationUserConfig } from './types'\nimport { resolve } from 'path'\nimport { AnvilOptions } from '@layerzerolabs/devtools-evm'\nimport { pipe } from 'fp-ts/lib/function'\nimport * as R from 'fp-ts/Record'\n\n/**\n * Turns `SimulationUserConfig` into `SimulationConfig` by supplying defaults\n *\n * @param {SimulationUserConfig} userConfig\n * @param {HardhatConfig} hardhatConfig\n * @returns {SimulationConfig}\n */\nexport const resolveSimulationConfig = (\n    userConfig: SimulationUserConfig,\n    hardhatConfig: HardhatConfig\n): SimulationConfig => ({\n    port: userConfig.port ?? 8545,\n    directory: resolve(hardhatConfig.paths.root, userConfig.directory ?? '.layerzero'),\n    overwriteAccounts: userConfig.overwriteAccounts ?? true,\n    anvil: {\n        // For now we'll hardcode the mnemonic we'll use to seed the accounts on the simulation networks\n        mnemonic: 'test test test test test test test test test test test junk',\n        ...userConfig.anvil,\n        // The host and port need to always point to 0.0.0.0:8545\n        // since anvil runs in the container that exposes this port on 0.0.0.0\n        host: '0.0.0.0',\n        port: 8545,\n    },\n})\n\n/**\n * Takes a portion of the hardhat networks config and turns the values into `AnvilOptions`\n * to be used by a simulation network container.\n *\n * This is used in the simulation generation phase where the compose files\n * for networks defined in hardhat config are being generated.\n *\n * The `Record<string, NetworkConfig>` is used instead of `NetworksConfig` type from hardhat\n * to avoid any type issues with special keys like `localhost` or `hardhat`.\n *\n * @param {SimulationConfig} config\n * @param {Record<string, NetworkConfig>} networksConfig\n * @returns {Record<string, AnvilOptions>} Object with the same keys as the networks config, with values mapped to `AnvilOptions`\n */\nexport const getAnvilOptionsFromHardhatNetworks = (\n    config: SimulationConfig,\n    networksConfig: Record<string, NetworkConfig>\n): Record<string, AnvilOptions> =>\n    pipe(\n        networksConfig,\n        // We want to drop all the networks that don't have URLs\n        R.filter(isHttpNetworkConfig),\n        // And map the network configs into AnvilOptions\n        R.map(\n            (networkConfig: HttpNetworkConfig): AnvilOptions => ({\n                ...config.anvil,\n                forkUrl: networkConfig.url,\n            })\n        )\n    )\n\n/**\n * Returns with overrides for hardhat network configuration.\n *\n * This, when merged with a hardhat config, will redirect the network calls to the local EVM nodes.\n *\n * @param {SimulationConfig} config\n * @param {Record<string, NetworkConfig>} networksConfig\n * @returns {Record<string, NetworkConfig>}\n */\nexport const getHardhatNetworkOverrides = (\n    config: SimulationConfig,\n    networksConfig: Record<string, NetworkConfig>\n): Record<string, NetworkConfig> =>\n    pipe(\n        networksConfig,\n        // We want to drop all the networks that don't have URLs\n        R.filter(isHttpNetworkConfig),\n        // We'll take the existing network configs and point them to our RPC proxy\n        //\n        // It's important that these configs are not saved to filesystem as they might contain\n        // sensitive data (and forgetting to ignore these files in git could lead to security breaches)\n        R.mapWithIndex(\n            (networkName, networkConfig): NetworkConfig => ({\n                ...networkConfig,\n                // We want to redirect this network to the local proxy\n                //\n                // This is the nginx server listening on the port we configured in the simulation configuration\n                url: new URL(networkName, `http://localhost:${config.port}`).toString(),\n                accounts: config.overwriteAccounts\n                    ? // When overwriting accounts, all the accounts will be switched to the anvil config\n                      // (or reasonable defaults if not provided)\n                      {\n                          mnemonic: config.anvil.mnemonic,\n                          // These need to be defaulted to the anvil options\n                          // (or the anvil defaults)\n                          //\n                          // See https://book.getfoundry.sh/reference/cli/anvil for anvil defaults\n                          count: config.anvil.count ?? 10,\n                          path: config.anvil.derivationPath ?? \"m/44'/60'/0'/0/\",\n                          // These will be hardcoded for now as anvil does not support setting these\n                          initialIndex: 0,\n                          passphrase: '',\n                      }\n                    : networkConfig.accounts,\n            })\n        )\n    )\n\n/**\n * Helper utility to pick network configs by their names / object keys.\n *\n * Similar to TypeScript `Pick` helper type, but in runtime.\n *\n * @param {string[]} networks List of networks to pick\n */\nexport const pickNetworkConfigs = (networks: string[]) =>\n    R.filterWithIndex<string, NetworkConfig>((networkName: string) => networks.includes(networkName))\n\n/**\n * Little helper utility that checks whether a network config is not a hardhat network config\n *\n * @param {NetworkConfig} networkConfig\n * @returns {boolean}\n */\nconst isHttpNetworkConfig = (networkConfig: NetworkConfig): networkConfig is HttpNetworkConfig =>\n    'url' in networkConfig && typeof networkConfig.url === 'string'\n","import '@/type-extensions'\n\nimport { TASK_LZ_TEST_SIMULATION_LOGS, TASK_LZ_TEST_SIMULATION_START } from '@/constants'\nimport { ActionType } from 'hardhat/types'\nimport { task } from 'hardhat/config'\nimport { types } from '@/cli'\nimport { printLogo } from '@layerzerolabs/io-devtools/swag'\nimport { LogLevel, createLogger, printJson, setDefaultLogLevel } from '@layerzerolabs/io-devtools'\nimport { mkdirSync, writeFileSync } from 'fs'\nimport { join } from 'path'\nimport { serializeDockerComposeSpec } from '@layerzerolabs/devtools'\nimport { createSimulationComposeSpec } from '@/simulation/compose'\nimport { assertDefinedNetworks } from '@/internal/assertions'\nimport { getEidsByNetworkName } from '@/runtime'\nimport { getAnvilOptionsFromHardhatNetworks, pickNetworkConfigs, resolveSimulationConfig } from '@/simulation'\nimport { dockerfile, nginxConf } from '@/simulation/assets'\nimport { spawnSync } from 'child_process'\nimport { EndpointId, Stage, endpointIdToStage } from '@layerzerolabs/lz-definitions'\n\nexport interface SimulationStartTaskArgs {\n    logLevel?: LogLevel\n    networks?: string[]\n    daemon?: boolean\n    stage?: Stage\n}\n\nconst action: ActionType<SimulationStartTaskArgs> = async (\n    { networks: networksArgument, daemon = false, logLevel = 'info', stage },\n    hre\n) => {\n    setDefaultLogLevel(logLevel)\n\n    printLogo()\n\n    const logger = createLogger()\n\n    // --stage cannot be used in conjunction with --networks\n    if (networksArgument != null && stage != null) {\n        logger.error(`--stage ${stage} cannot be used in conjunction with --networks ${networksArgument.join(',')}`)\n\n        process.exit(1)\n    }\n\n    // And we create a filtering predicate for the stage argument\n    const isOnStage = stage == null ? () => true : (eid: EndpointId) => endpointIdToStage(eid) === stage\n\n    // Let's grab the networks that will be included in the simulation\n    const networks = networksArgument\n        ? // Here we need to check whether the networks have been defined in hardhat config\n          assertDefinedNetworks(networksArgument)\n        : //  But here we are taking them from hardhat config so no assertion is necessary\n          Object.entries(getEidsByNetworkName()).flatMap(([networkName, eid]) =>\n              eid != null && isOnStage(eid) ? [networkName] : []\n          )\n\n    // We only continue if we have any networks with eid\n    //\n    // The eid is not really a requirement - we could spin up forked nodes for any\n    // network defined in the hardhat config - it's just a way of limiting this simulation to LayerZero networks\n    if (networks.length === 0) {\n        logger.warn(`No networks with eid configured, exiting`)\n\n        return\n    }\n\n    logger.info(`Will create a simulation configuration for networks ${networks.join(', ')}`)\n\n    // Grab the simulation user config from hardhat user config\n    const simulationUserConfig = hre.userConfig.layerZero?.experimental?.simulation ?? {}\n    logger.verbose(`Using simulation user config:\\n${printJson(simulationUserConfig)}`)\n\n    // Resolve the defaults for the simulation config\n    const simulationConfig = resolveSimulationConfig(simulationUserConfig, hre.config)\n    logger.verbose(`Resolved simulation config:\\n${printJson(simulationConfig)}`)\n\n    // Grab only the network configs we are going to need for the simulation\n    const networkConfigs = pickNetworkConfigs(networks)(hre.config.networks)\n\n    // Turn the network configs into anvil options\n    const anvilOptions = getAnvilOptionsFromHardhatNetworks(simulationConfig, networkConfigs)\n    logger.verbose(`The anvil config is:\\n${printJson(anvilOptions)}`)\n\n    // Now create the compose file\n    const composeSpec = createSimulationComposeSpec(simulationConfig, anvilOptions)\n    const serializedComposeSpec = serializeDockerComposeSpec(composeSpec)\n\n    // And finally we write all the required file artifacts to filesystem\n    logger.verbose(`Making sure directory ${simulationConfig.directory} exists`)\n    mkdirSync(simulationConfig.directory, { recursive: true })\n\n    const dockerfilePath = join(simulationConfig.directory, 'Dockerfile')\n    logger.debug(`Writing simulation Dockerfile to ${dockerfilePath}`)\n    writeFileSync(dockerfilePath, dockerfile)\n\n    const nginxConfPath = join(simulationConfig.directory, 'nginx.conf')\n    logger.debug(`Writing simulation nginx configuration file to ${nginxConfPath}`)\n    writeFileSync(nginxConfPath, nginxConf)\n\n    const dockerComposePath = join(simulationConfig.directory, 'docker-compose.yaml')\n    logger.debug(`Writing simulation docker compose spec file to ${dockerComposePath}`)\n    writeFileSync(dockerComposePath, serializedComposeSpec)\n\n    // Spawn docker compose up command, piping the stdout and stderr to the current shell\n    //\n    // The error reporting on this part should be improved - we should check that \"docker\" and \"docker compose\"\n    // are known commands before we go ahead and try executing them\n    try {\n        if (daemon) {\n            logger.info(`Starting simulation in the background`)\n            logger.info(\n                `Use 'LZ_ENABLE_EXPERIMENTAL_SIMULATION=1 npx hardhat ${TASK_LZ_TEST_SIMULATION_LOGS}' to view the network logs`\n            )\n        } else {\n            logger.info(`Starting simulation`)\n        }\n\n        logger.verbose(`Spawning docker compose up command for ${dockerComposePath}`)\n\n        // This is a very quick and dirty way to pass an optional --wait argument to docker compose up\n        const additionalUpArgs: string[] = daemon ? ['--wait'] : []\n\n        const result = spawnSync('docker', ['compose', '-f', dockerComposePath, 'up', ...additionalUpArgs], {\n            stdio: 'inherit',\n        })\n\n        if (result.status !== 0) {\n            throw new Error(`docker compose up command failed with exit code ${result.status}`)\n        }\n    } catch (error) {\n        logger.error(`Failed to spawn docker compose up command for ${dockerComposePath}: ${error}`)\n\n        process.exitCode = 1\n\n        return\n    }\n}\n\nif (process.env.LZ_ENABLE_EXPERIMENTAL_SIMULATION) {\n    task(TASK_LZ_TEST_SIMULATION_START, 'Start LayzerZero omnichain simulation', action)\n        .addParam('logLevel', 'Logging level. One of: error, warn, info, verbose, debug, silly', 'info', types.logLevel)\n        .addParam('networks', 'Comma-separated list of networks to simulate', undefined, types.csv, true)\n        .addParam('stage', 'Chain stage. One of: mainnet, testnet, sandbox', undefined, types.stage, true)\n        .addFlag('daemon', 'Start the simulation in the background')\n}\n","import { pipe } from 'fp-ts/lib/function'\nimport * as RR from 'fp-ts/ReadonlyRecord'\nimport type { ComposeSpec, ComposeSpecService } from '@layerzerolabs/devtools'\nimport { type AnvilOptions, createAnvilCliOptions } from '@layerzerolabs/devtools-evm'\nimport type { ComposeSpecServices } from '@layerzerolabs/devtools'\nimport type { SimulationConfig } from './types'\n\n/**\n * Creates a docker compose service specification for an anvil-based EVM node\n *\n * @param {AnvilOptions} anvilOptions\n * @returns {ComposeSpecService}\n */\nexport const createEvmNodeServiceSpec = (anvilOptions: AnvilOptions): ComposeSpecService => ({\n    // This service references a Dockerfile that is copied\n    // next to the resulting docker-compose.yaml\n    //\n    // The source for this Dockerfile is located in src/simulation/assets/Dockerfile.conf\n    build: {\n        dockerfile: 'Dockerfile',\n        target: 'node-evm',\n    },\n    command: ['anvil', ...createAnvilCliOptions(anvilOptions)],\n})\n\n/**\n * Creates a docker compose service specification for an nginx-based proxy service\n * that proxies requests to underlying EVM nodes (or their RPC URLs to be mor precise)\n *\n * @param {number} port\n * @param {ComposeSpecServices} networkServices\n * @returns {ComposeSpecService}\n */\nexport const createEvmNodeProxyServiceSpec = (\n    port: number,\n    networkServices: ComposeSpecServices\n): ComposeSpecService => ({\n    // This service references a Dockerfile that is copied\n    // next to the resulting docker-compose.yaml\n    //\n    // The source for this Dockerfile is located in src/simulation/assets/Dockerfile.conf\n    build: {\n        dockerfile: 'Dockerfile',\n        target: 'proxy-evm',\n    },\n    // This service will expose its internal 8545 port to a host port\n    //\n    // The internal 8545 port is hardcoded both here and in the nginx.conf file,\n    // the source for which is located in src/simulation/assets/nginx.conf\n    ports: [`${port}:8545`],\n    depends_on: pipe(\n        networkServices,\n        // This service will depend on the RPCs to be healthy\n        // so we'll take the networkServices object and replace\n        // the values with service_healthy condition\n        RR.map(() => ({\n            condition: 'service_healthy',\n        }))\n    ),\n})\n\n/**\n * Creates a docker compose spec with a set of anvil-based EVM nodes\n * and a single proxy server that proxies requests to these nodes.\n *\n * @param {SimulationConfig} config\n * @param {Record<string, AnvilOptions>} networks\n * @returns {ComposeSpec}\n */\nexport const createSimulationComposeSpec = (\n    config: SimulationConfig,\n    networks: Record<string, AnvilOptions>\n): ComposeSpec => ({\n    services: pipe(\n        networks,\n        // First we turn the networks into docker compose specs for EVM nodes\n        RR.map(createEvmNodeServiceSpec),\n        (networkServiceSpecs) =>\n            // Then we add the RPC proxy server\n            //\n            // There is a small edge case here that we can address\n            // if it ever comes up: if a network is called 'rpc', this compose file\n            // will not work.\n            //\n            // The fix for this is to prefix all networks with something like network-xxx\n            // but we can do that if ever this usecase comes up\n            pipe(\n                networkServiceSpecs,\n                RR.upsertAt('rpc', createEvmNodeProxyServiceSpec(config.port, networkServiceSpecs))\n            )\n    ),\n})\n","ARG FOUNDRY_VERSION=nightly-156cb1396b7076c6f9cb56f3719f8c90f7f52064\nARG ALPINE_VERSION=3.18\n\n#   .-.-.   .-.-.   .-.-.   .-.-.   .-.-.   .-.-.   .-.-.   .-.-\n#  / / \\ \\ / / \\ \\ / / \\ \\ / / \\ \\ / / \\ \\ / / \\ \\ / / \\ \\ / / \\\n# `-'   `-`-'   `-`-'   `-`-'   `-`-'   `-`-'   `-`-'   `-`-'\n#\n#             Image that gives us the foundry tools\n#\n#   .-.-.   .-.-.   .-.-.   .-.-.   .-.-.   .-.-.   .-.-.   .-.-\n#  / / \\ \\ / / \\ \\ / / \\ \\ / / \\ \\ / / \\ \\ / / \\ \\ / / \\ \\ / / \\\n# `-'   `-`-'   `-`-'   `-`-'   `-`-'   `-`-'   `-`-'   `-`-'\nFROM ghcr.io/foundry-rs/foundry:$FOUNDRY_VERSION AS foundry\n\n#   .-.-.   .-.-.   .-.-.   .-.-.   .-.-.   .-.-.   .-.-.   .-.-\n#  / / \\ \\ / / \\ \\ / / \\ \\ / / \\ \\ / / \\ \\ / / \\ \\ / / \\ \\ / / \\\n# `-'   `-`-'   `-`-'   `-`-'   `-`-'   `-`-'   `-`-'   `-`-'\n#\n#               Image that starts an EVM node\n#\n#   .-.-.   .-.-.   .-.-.   .-.-.   .-.-.   .-.-.   .-.-.   .-.-\n#  / / \\ \\ / / \\ \\ / / \\ \\ / / \\ \\ / / \\ \\ / / \\ \\ / / \\ \\ / / \\\n# `-'   `-`-'   `-`-'   `-`-'   `-`-'   `-`-'   `-`-'   `-`-'\nFROM alpine:$ALPINE_VERSION AS node-evm\n\nSTOPSIGNAL SIGINT\n\n# We will provide a default healthcheck (that assumes that the netowrk is running on the default port 8545)\nHEALTHCHECK --timeout=2s --interval=2s --retries=20 CMD cast block --rpc-url http://localhost:8545/ latest\n\n# Get anvil\nCOPY --from=foundry /usr/local/bin/anvil /usr/local/bin/anvil\n\n# Get cast for healthcheck\nCOPY --from=foundry /usr/local/bin/cast /usr/local/bin/cast\n\n#   .-.-.   .-.-.   .-.-.   .-.-.   .-.-.   .-.-.   .-.-.   .-.-\n#  / / \\ \\ / / \\ \\ / / \\ \\ / / \\ \\ / / \\ \\ / / \\ \\ / / \\ \\ / / \\\n# `-'   `-`-'   `-`-'   `-`-'   `-`-'   `-`-'   `-`-'   `-`-'\n#\n#           Image that starts an nginx proxy server\n#\n#   .-.-.   .-.-.   .-.-.   .-.-.   .-.-.   .-.-.   .-.-.   .-.-\n#  / / \\ \\ / / \\ \\ / / \\ \\ / / \\ \\ / / \\ \\ / / \\ \\ / / \\ \\ / / \\\n# `-'   `-`-'   `-`-'   `-`-'   `-`-'   `-`-'   `-`-'   `-`-'\nFROM nginx:alpine$ALPINE_VERSION AS proxy-evm\n\nCOPY ./nginx.conf /etc/nginx/nginx.conf\n\nHEALTHCHECK --timeout=2s --interval=2s --retries=20 CMD curl -f http://0.0.0.0:8545/health-check\n\n","events {}\n\nhttp {\n  # We will modify the log  format to include the target_network\n  log_format proxied '$remote_addr - $remote_user [$time_local] '\n                     '\"$request\" $status $body_bytes_sent '\n                     '\"$http_referer\" \"$http_user_agent\" '\n                     'Network: \"$target_network\"';\n\n  server {\n    # This proxy server will listen on port 8545\n    # \n    # Even though it's not ideal to have this hardcoded, this port\n    # will be remapped to a desired host port using docker compose,\n    # the only issue this hardcoding brings is the fact that this port\n    # needs to match the container port in the compose spec\n    listen 8545;\n    listen [::]:8545;\n\n    # We will add a simple endpoint for healthcheck\n    location /health-check {\n      access_log\toff;\n      error_log\toff;\n      return 200 'ok';\n    }\n\n    # In this section we'll proxy all the requests to this server\n    # to the respective network nodes\n    # \n    # The requests are proxied based on the first path segment:\n    # \n    # http://localhost/fuji -> http://fuji:8545/\n    # \n    # For now the remaining path segments are not being preserved:\n    # \n    # # http://localhost/fuji/some/url -> http://fuji:8545/\n    location / {\n      # Set the log format to be our custom 'proxied' log format\n      access_log /var/log/nginx/access.log proxied;\n\n      resolver 127.0.0.11;\n      autoindex off;\n\n      # This variable will hold the name of the network to proxy to\n      set $target_network '';\n\n      # Extract the first path segment from the request URI\n      if ($request_uri ~* ^/(?<target_network>[^/]+)(/.*)?$) {\n        set $target_network $1;\n      }\n\n      # Proxy the request to the appropriate network\n      proxy_pass http://$target_network:8545/;\n    }\n  }\n}","import '@/type-extensions'\n\nimport { TASK_LZ_TEST_SIMULATION_START, TASK_LZ_TEST_SIMULATION_STOP } from '@/constants'\nimport { ActionType } from 'hardhat/types'\nimport { task } from 'hardhat/config'\nimport { printLogo } from '@layerzerolabs/io-devtools/swag'\nimport { LogLevel, createLogger, isFile, printJson, setDefaultLogLevel } from '@layerzerolabs/io-devtools'\nimport { types } from '@/cli'\nimport { resolveSimulationConfig } from '@/simulation/config'\nimport { join } from 'path'\nimport { spawnSync } from 'child_process'\nimport { rmSync } from 'fs'\n\nexport interface SimulationStopTaskArgs {\n    logLevel?: LogLevel\n}\n\nconst action: ActionType<SimulationStopTaskArgs> = async ({ logLevel = 'info' }, hre) => {\n    setDefaultLogLevel(logLevel)\n\n    printLogo()\n\n    const logger = createLogger()\n\n    // Grab the simulation user config from hardhat user config\n    const simulationUserConfig = hre.userConfig.layerZero?.experimental?.simulation ?? {}\n    logger.verbose(`Using simulation user config:\\n${printJson(simulationUserConfig)}`)\n\n    // Resolve the defaults for the simulation config\n    const simulationConfig = resolveSimulationConfig(simulationUserConfig, hre.config)\n    logger.verbose(`Resolved simulation config:\\n${printJson(simulationConfig)}`)\n\n    // Check that the docker compose file exists\n    const dockerComposePath = join(simulationConfig.directory, 'docker-compose.yaml')\n    if (!isFile(dockerComposePath)) {\n        logger.warn(`Could not find simulation docker compose file '${dockerComposePath}'`)\n        logger.warn(`Did you run 'npx hardhat ${TASK_LZ_TEST_SIMULATION_START}'?`)\n\n        process.exitCode = 1\n\n        return\n    }\n\n    // Spawn docker compose down command, piping the stdout and stderr to the current shell\n    //\n    // The error reporting on this part should be improved - we should check that \"docker\" and \"docker compose\"\n    // are known commands before we go ahead and try executing them\n    try {\n        logger.info(`Stopping simulation`)\n        logger.verbose(`Spawning docker compose down command for ${dockerComposePath}`)\n\n        spawnSync('docker', ['compose', '-f', dockerComposePath, 'down'], {\n            stdio: 'inherit',\n        })\n    } catch (error) {\n        logger.error(`Failed to spawn docker compose down command for ${dockerComposePath}: ${error}`)\n\n        process.exitCode = 1\n\n        return\n    } finally {\n        try {\n            rmSync(simulationConfig.directory, { force: true, recursive: true })\n        } catch (error) {\n            logger.error(`Failed to delete '${simulationConfig.directory}': ${error}`)\n        }\n    }\n}\n\nif (process.env.LZ_ENABLE_EXPERIMENTAL_SIMULATION) {\n    task(TASK_LZ_TEST_SIMULATION_STOP, 'Stop LayerZero omnichain simulation', action).addParam(\n        'logLevel',\n        'Logging level. One of: error, warn, info, verbose, debug, silly',\n        'info',\n        types.logLevel\n    )\n}\n","import { types } from '@/cli'\nimport { SUBTASK_LZ_SIGN_AND_SEND } from '@/constants'\nimport { createSignAndSendFlow, type OmniSignerFactory, type OmniTransaction } from '@layerzerolabs/devtools'\nimport type { Logger } from '@layerzerolabs/io-devtools'\nimport { subtask } from 'hardhat/config'\n\nexport interface SignAndSendTaskArgs {\n    ci?: boolean\n    logger?: Logger\n    transactions: OmniTransaction[]\n    createSigner: OmniSignerFactory\n}\n\nsubtask(\n    SUBTASK_LZ_SIGN_AND_SEND,\n    'Sign and send a list of transactions using a local signer',\n    ({ transactions, ...args }: SignAndSendTaskArgs) => createSignAndSendFlow(args)({ transactions })\n)\n    .addFlag('ci', 'Continuous integration (non-interactive) mode. Will not ask for any input from the user')\n    .addParam('transactions', 'List of OmniTransaction objects', undefined, types.any)\n    .addParam('createSigner', 'Function that creates a signer for a particular network', undefined, types.fn)\n    .addParam('logger', 'Logger object (see @layerzerolabs/io-devtools', undefined, types.any, true)\n    .addParam('onFailure', 'Function that handles sign & send failures', undefined, types.fn, true)\n","import { task } from 'hardhat/config'\nimport type { ActionType } from 'hardhat/types'\nimport { TASK_LZ_EXPORT_DEPLOYMENTS_TYPESCRIPT } from '@/constants/tasks'\nimport { OutputFile, createIncludeDirent, generate, generatorTypeScript } from '@layerzerolabs/export-deployments'\nimport { createLogger, pluralizeNoun, printBoolean, setDefaultLogLevel } from '@layerzerolabs/io-devtools'\n\nimport { printLogo } from '@layerzerolabs/io-devtools/swag'\nimport { types } from '@/cli'\n\ninterface TaskArgs {\n    contracts?: string[]\n    networks?: string[]\n    outDir?: string\n    logLevel?: string\n}\n\nconst action: ActionType<TaskArgs> = async (\n    { networks, contracts, logLevel = 'info', outDir = 'generated' },\n    hre\n): Promise<OutputFile[]> => {\n    printLogo()\n\n    // We'll set the global logging level to get as much info as needed\n    setDefaultLogLevel(logLevel)\n\n    // And we'll create a logger for ourselves\n    const logger = createLogger()\n\n    // We just go ahead and export, not a care in the world\n    const results = generate({\n        // Since we are in a hardhat project, the deployments path is coming from the config\n        deploymentsDir: hre.config.paths.deployments,\n        outDir,\n        includeDeploymentFile: createIncludeDirent(contracts),\n        includeNetworkDir: createIncludeDirent(networks),\n        generator: generatorTypeScript,\n    })\n\n    logger.info(\n        `${printBoolean(true)} ${pluralizeNoun(results.length, `Generated 1 file:`, `Generated ${results.length} files`)}`\n    )\n\n    for (const { path } of results) {\n        logger.info(`\\t${path}`)\n    }\n\n    return results\n}\n\ntask(TASK_LZ_EXPORT_DEPLOYMENTS_TYPESCRIPT, 'Export deployments as TypeScript files', action)\n    .addParam(\n        'networks',\n        'List of comma-separated networks. If not provided, all networks will be deployed',\n        undefined,\n        types.csv,\n        true\n    )\n    .addParam(\n        'contracts',\n        'List of comma-separated contract names. If not provided, all contracts will be exported',\n        undefined,\n        types.csv,\n        true\n    )\n    .addParam('logLevel', 'Logging level. One of: error, warn, info, verbose, debug, silly', 'info', types.logLevel)\n","import '@/type-extensions'\n\nimport { ActionType } from 'hardhat/types'\nimport { task } from 'hardhat/config'\nimport { TASK_LZ_VALIDATE_SAFE_CONFIGS } from '@/constants'\nimport { createLogger, printBoolean } from '@layerzerolabs/io-devtools'\nimport { printLogo } from '@layerzerolabs/io-devtools/swag'\n\nconst SAFE_CONFIG_KEY = 'safeConfig'\n\nconst logger = createLogger()\n\n// @dev safeURLs are only considered valid if they are listed here: https://docs.safe.global/core-api/transaction-service-supported-networks\nconst validateSafeConfig = async (config: any): Promise<boolean> => {\n    if (!config.safeAddress) {\n        logger.error(`${printBoolean(false)} Missing safeAddress`)\n        return false\n    }\n\n    if (!config.safeUrl) {\n        logger.error(`${printBoolean(false)} Missing safeUrl`)\n        return false\n    }\n\n    // Construct the API URL to read safe\n    const apiUrl = `${config.safeUrl}/api/v1/safes/${config.safeAddress}/`\n\n    try {\n        // Make the API request to read safe\n        const response = await fetch(apiUrl)\n\n        // Check if the response is successful\n        if (!response.ok) {\n            return false\n        }\n\n        return true\n    } catch (error) {\n        if (error instanceof Error) {\n            logger.error(`Validation failed: ${error.message}`)\n        } else {\n            // Handle other types of errors (if any)\n            logger.error('An unknown error occurred')\n        }\n\n        return false\n    }\n}\n\nconst action: ActionType<unknown> = async (_, hre) => {\n    printLogo()\n\n    const networkNames = Object.keys(hre.userConfig.networks || {})\n\n    logger.info(`...Validating safe configs for ${networkNames.join(', ')}...`)\n\n    for (const networkName of networkNames) {\n        const networkConfig = hre.userConfig.networks?.[networkName]\n\n        if (networkConfig && SAFE_CONFIG_KEY in networkConfig) {\n            const isValid = await validateSafeConfig(networkConfig.safeConfig)\n\n            if (!isValid) {\n                throw new Error(`${printBoolean(false)} Safe config validation failed for network: ${networkName}`)\n            }\n        }\n    }\n\n    logger.info(`${printBoolean(true)} All safe configs are valid!`)\n}\ntask(TASK_LZ_VALIDATE_SAFE_CONFIGS, 'Validate safe configs in hardhat.config.ts', action)\n","import '@/type-extensions'\n\nimport { ActionType } from 'hardhat/types'\nimport { task, types } from 'hardhat/config'\nimport { TASK_LZ_VALIDATE_RPCS } from '@/constants'\nimport { createLogger, printBoolean } from '@layerzerolabs/io-devtools'\nimport { assertDefinedNetworks } from '@/internal/assertions'\nimport { printLogo } from '@layerzerolabs/io-devtools/swag'\nimport { getEidsByNetworkName } from '@/runtime'\nimport { BaseProvider, JsonRpcProvider, WebSocketProvider } from '@ethersproject/providers'\nimport { types as cliTypes } from '@/cli'\nimport { EndpointId, Stage, endpointIdToStage } from '@layerzerolabs/lz-definitions'\nimport { pickNetworkConfigs } from '@/simulation'\n\nconst RPC_URL_KEY = 'url'\n\nconst HTTP_URL = 'http://'\nconst HTTPS_URL = 'https://'\n\nconst WS_URL = 'ws://'\nconst WSS_URL = 'wss://'\n\nconst TIMEOUT = 1000 // 1 second\n\nconst logger = createLogger()\n\ninterface TaskArguments {\n    timeout: number\n    networks?: string[]\n    stage?: Stage\n}\n\nconst getProvider = async (rpcUrl: string, networkName: string): Promise<BaseProvider> => {\n    let provider\n    if (rpcUrl.startsWith(HTTP_URL) || rpcUrl.startsWith(HTTPS_URL)) {\n        provider = new JsonRpcProvider(rpcUrl)\n    } else if (rpcUrl.startsWith(WS_URL) || rpcUrl.startsWith(WSS_URL)) {\n        provider = new WebSocketProvider(rpcUrl)\n    } else {\n        logger.error(`Unsupported RPC protocol in network: ${networkName}`)\n    }\n\n    return provider\n}\n\nconst action: ActionType<TaskArguments> = async (taskArgs, hre) => {\n    printLogo()\n\n    // --stage cannot be used in conjunction with --networks\n    if (taskArgs.networks != null && taskArgs.stage != null) {\n        logger.error(\n            `--stage ${taskArgs.stage} cannot be used in conjunction with --networks ${taskArgs.networks.join(',')}`\n        )\n\n        process.exit(1)\n    }\n\n    // And we create a filtering predicate for the stage argument\n    const isOnStage =\n        taskArgs.stage == null ? () => true : (eid: EndpointId) => endpointIdToStage(eid) === taskArgs.stage\n\n    // Let's grab the networks that will be validated\n    const networks = taskArgs.networks\n        ? // Here we need to check whether the networks have been defined in hardhat config\n          pickNetworkConfigs(assertDefinedNetworks(taskArgs.networks))(hre.config.networks)\n        : taskArgs.stage //  But here we are taking them from hardhat config so no assertion is necessary\n          ? pickNetworkConfigs(\n                Object.entries(getEidsByNetworkName()).flatMap(([networkName, eid]) =>\n                    eid != null && isOnStage(eid) ? [networkName] : []\n                )\n            )(hre.config.networks)\n          : hre.config.networks\n\n    const eidByNetworkName = getEidsByNetworkName(hre)\n\n    logger.info(\n        `========== Validating RPC URLs for networks: ${taskArgs.networks?.join(', ') || Object.keys(eidByNetworkName).join(', ')}`\n    )\n\n    const networksWithInvalidRPCs: string[] = []\n\n    await Promise.all(\n        Object.entries(eidByNetworkName).map(async ([networkName, eid]) => {\n            if (!eid) {\n                logger.info(`No eid found for network ${networkName}, skipping`)\n                return\n            }\n            const rpcUrl = networks[networkName]?.[RPC_URL_KEY]\n            if (!rpcUrl) {\n                logger.info(`No RPC URL found for network ${networkName}, skipping`)\n                return\n            }\n\n            const provider: BaseProvider = await getProvider(rpcUrl, networkName)\n            if (!provider) {\n                networksWithInvalidRPCs.push(networkName)\n                logger.error(`Error fetching provider for network: ${networkName}`)\n                return\n            }\n\n            return Promise.race([\n                provider.getBlockNumber(),\n                new Promise<void>((_, reject) => setTimeout(reject, taskArgs.timeout)),\n            ]).then(\n                (block) => {\n                    return !!block\n                },\n                () => {\n                    networksWithInvalidRPCs.push(networkName)\n                }\n            )\n        })\n    )\n\n    if (networksWithInvalidRPCs.length !== 0) {\n        logger.error(\n            `${printBoolean(false)} ========== RPC URL validation failed for network(s): ${networksWithInvalidRPCs.join(', ')}`\n        )\n    } else {\n        logger.info(`${printBoolean(true)} ========== All RPC URLs are valid!`)\n    }\n}\ntask(\n    TASK_LZ_VALIDATE_RPCS,\n    'Validate RPC URLs in hardhat.config.ts. RPCs are only considered valid if they use the https or wss protocol and respond within the specified timeout.',\n    action\n)\n    .addParam(\n        'timeout',\n        `Maximum amount of time (in milliseconds) that the RPC URLs have to respond. If unspecified, default timeout of ${TIMEOUT}ms will be used.`,\n        TIMEOUT,\n        types.int,\n        true\n    )\n    .addParam('networks', 'Comma-separated list of networks to simulate', undefined, cliTypes.csv, true)\n    .addParam('stage', 'Chain stage. One of: mainnet, testnet, sandbox', undefined, cliTypes.stage, true)\n"]}